{"meta":{"title":"lwy的博客","subtitle":"欢迎大家与我交流","description":"茫茫人海，总会与你相遇","author":"lwy","url":"https://lwy0518.github.io","root":"/"},"pages":[{"title":"404","date":"2021-12-06T07:38:28.000Z","updated":"2021-12-06T07:39:37.088Z","comments":true,"path":"404/index.html","permalink":"https://lwy0518.github.io/404/index.html","excerpt":"","text":"title: ‘404’permalink: /404date: 2020-10-16 15:19:35comments: falselayout: false ---"},{"title":"book","date":"2021-12-07T11:10:56.000Z","updated":"2021-12-07T11:10:56.396Z","comments":true,"path":"book/index.html","permalink":"https://lwy0518.github.io/book/index.html","excerpt":"","text":""},{"title":"categories","date":"2021-12-06T12:13:37.000Z","updated":"2021-12-06T12:14:34.617Z","comments":true,"path":"categories/index.html","permalink":"https://lwy0518.github.io/categories/index.html","excerpt":"","text":""},{"title":"留言板","date":"2021-12-07T06:33:36.000Z","updated":"2021-12-08T07:21:43.539Z","comments":true,"path":"guestbook/index.html","permalink":"https://lwy0518.github.io/guestbook/index.html","excerpt":"","text":"欢迎来到我的博客！ 欢迎在这里留言！任何问题都可以在这里留言，我会及时回复的，添加QQ或微信可以获得更快的回复速度，在侧边栏扫描二维码即可。"},{"title":"与我相关","date":"2021-12-07T02:15:02.000Z","updated":"2021-12-22T03:33:24.416Z","comments":true,"path":"about/index.html","permalink":"https://lwy0518.github.io/about/index.html","excerpt":"","text":"🏠基本信息 姓名：李文远 性别：男 爱好：打乒乓球、听歌 … … ✔技能 java SQL ❓ 了解我 Github：https://github.com/lwy0518 QQ：1024325635 WeChat：15946947900 知乎： https://www.zhihu.com/people/nan-cheng-ni-liu-86-1 🏫教育经历 2020.9 - 至今 ： 华南师范大学 2016.9 - 2020.7 ： 江西理工大学 2013.9 - 2016.7 ：临川一中 2010.9 - 2013.7 ： 大岗中学 … …"},{"title":"Metaverse（元宇宙）","date":"2021-12-07T09:22:30.000Z","updated":"2021-12-07T11:32:55.974Z","comments":true,"path":"top/index.html","permalink":"https://lwy0518.github.io/top/index.html","excerpt":"","text":"元宇宙"},{"title":"tools","date":"2021-12-07T10:51:44.000Z","updated":"2021-12-11T05:05:21.038Z","comments":true,"path":"tools/index.html","permalink":"https://lwy0518.github.io/tools/index.html","excerpt":"","text":"latex 在线表格生成器 latex 在线公式生成器 markdown 在线编辑 抽象语法树在线生成 阿里云加速 ReadPaper"},{"title":"tags","date":"2021-12-06T12:14:59.000Z","updated":"2021-12-06T12:15:17.173Z","comments":true,"path":"tags/index.html","permalink":"https://lwy0518.github.io/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"偏序介绍","slug":"偏序介绍","date":"2021-12-27T13:21:29.000Z","updated":"2021-12-30T02:20:47.838Z","comments":true,"path":"2021/12/27/偏序介绍/","link":"","permalink":"https://lwy0518.github.io/2021/12/27/%E5%81%8F%E5%BA%8F%E4%BB%8B%E7%BB%8D/","excerpt":"偏序介绍 偏序 全序 偏序与全序区别 Lattice（格） Lattice（格） Semilattice（半格） Complete Lattice（全格） Product Lattice（乘积格） 上界与下界","text":"偏序介绍 偏序 全序 偏序与全序区别 Lattice（格） Lattice（格） Semilattice（半格） Complete Lattice（全格） Product Lattice（乘积格） 上界与下界 偏序 参考链接 全序与偏序 偏序 定义 Partiallyordered set，简写poset 设R是集合A上的一个二元关系，若R满足： Ⅰ 自反性：对任意x∈A，有xRx； Ⅱ 反对称性（即反对称关系）：对任意x,y∈A，若xRy，且yRx，则x=y； Ⅲ 传递性：对任意x, y,z∈A，若xRy，且yRz，则xRz。 则称R为A上的偏序关系，通常记作≼。注意这里的≼不必是指一般意义上的“小于或等于”。 若然有x≼y，我们也说x排在y前面（x precedes y）。 分类 严格偏序，反自反偏序 给定集合S，“&lt;”是S上的二元关系，若“&lt;”满足： 反自反性：∀a∈S，有a≮a； 非对称性：∀a，b∈S，a&lt;b ⇒ b≮a； 传递性：∀a，b，c∈S，a&lt;b且b&lt;c，则a&lt;c； 则称“&lt;”是S上的严格偏序或反自反偏序 严格偏序与有向无环图（dag）有直接的对应关系。一个集合上的严格偏序的关系图就是一个有向无环图。其传递闭包是它自己 非严格偏序，自反偏序 给定集合S，“≤”是S上的二元关系，若“≤”满足： 自反性：∀a∈S，有a≤a； 反对称性：∀a，b∈S，a≤b且b≤a，则a=b； 传递性：∀a，b，c∈S，a≤b且b≤c，则a≤c； 则称“≤”是S上的非严格偏序或自反偏序。 例子 假设有 A={1,2,3,4}，假设R是集合A上的关系：{&lt;1,1&gt;,&lt;2,2&gt;,&lt;3,3&gt;,&lt;4,4&gt;,&lt;1,2&gt;,&lt;1,4&gt;,&lt;2,4&gt;,&lt;3,4&gt;}，那么： 自反性：可以看到 &lt;1,1&gt;,&lt;2,2&gt;,&lt;3,3&gt;,&lt;4,4&gt; 都在R中，满足。 反对称性：由于 &lt;1,1&gt;,&lt;2,2&gt;,&lt;3,3&gt;,&lt;4,4&gt; 不属于 x !=y ，所以不考虑这4种，对于 &lt;1,2&gt;，有 &lt;2,1&gt; 不在R中；对于&lt;2,4&gt; 有&lt;4,2&gt;不在R中；对于&lt;3,4&gt; 有&lt;4,3&gt; 不在 R中，满足。 传递性：&lt;1,1&gt;&lt;1,2&gt;在R中，并且&lt;1,2&gt;在R中；&lt;1,1&gt;&lt;1,4&gt;在R中，并且&lt;1,4&gt;在R中；&lt;2,2&gt;&lt;2,4&gt;在R中，并且&lt;2,4&gt;在R中；&lt;3,3&gt;&lt;3,4&gt;在R中，并且&lt;3,4&gt;在R中；等等其他，满足。 所以说R是偏序关系。 全序 定义 如果R是A上的偏序关系，那么对于任意的A集合上的 x,y，都有 x &lt;= y，或者 y &lt;= x，二者必居其一，那么则称R是A上的全序关系 设集合X上有一全序关系，如果我们把这种关系用 ≤ 表述，则下列陈述对于 X 中的所有 a, b 和 c 成立： 如果 a ≤ b 且 b ≤ a 则 a = b (反对称性) 如果 a ≤ b 且 b ≤ c 则 a ≤ c (传递性) a ≤ b 或 b ≤ a (完全性) 例子 假设有 A={a,b,c}，假设R是集合A上的关系：{&lt;a,a&gt;,&lt;b,b&gt;,&lt;c,c&gt;,&lt;a,b&gt;,&lt;a,c&gt;,&lt;b,c&gt;}和上述一样，可以证明具有自反性，反对称性，传递性，所以是偏序的，有因为有 &lt;a,b&gt;,&lt;a,c&gt;,&lt;b,c&gt;， 也就是说两两关系都有了，所以满足对于任意的A集合上的 x,y，都有 x &lt;= y，或者 y &lt;= x，二者必居其一，所以说是全序关系 区别 偏序集合：配备了偏序关系的集合。 偏序：只对部分要元素成立关系（部分可比） 集合内只有部分元素之间在这个关系下是可以比较的。 比如：比如复数集中并不是所有的数都可以比较大小，那么“大小”就是复数集的一个偏序关系 全序集合：配备了全序关系的集合。 全序：对集合中任意两个元素都有关系 集合内任何一对元素在在这个关系下都是相互可比较的。 比如：有限长度的序列按字典序是全序的。最常见的是单词在字典中是全序的 例子 集合的包含关系是一种偏序。 在正整数集中定义偏序：若a能整除b，我们就记为a≺b 显然它满足序公理。但整数集中，不是任何两个数都存在整除关系，这个关系是局部的（partial），太“偏颇”，于是被称为偏序 Lattice 参考链接 格 Lattice（格） 定义 如果一个偏序集的任意两个元素都有最小上界和最大下界，那么这一偏序集是一个格 Semilattice（半格） 定义 最小上界和最大下界只存在一个的偏序集称半格，只存在最小上界称为“join semilattice”，只存在最大下界称为“meet semilattice” Complete Lattice（全格） 定义 一个偏序集的任意子集均存在最小上界和最大下界，那么这个偏序集成为全格 特点 每个全格都存在一个最大元素 top（⊤=⊔P）和最小元素bottom（⊥=⊓P） 所有元素有限的格（finite lattice）均是全格。（反之不成立） Product Lattice（乘积格） 给定n个lattice，L1 = (P1, ⊑1), L2 = (P2, ⊑2), …, Ln = (Pn, ⊑n)，如果每个lattice都有对应的⊔i(最小上界)和⊓i(最大下界)，那么我们得到一个Product Lattice Ln = (P, ⊑)并有以下四个定义： 1.P = P1 × … × Pn 2.(x1, …, xn) ⊑ (y1, …, yn) ⟺ (x1 ⊑ y1) ∧ … ∧ (xn ⊑ yn) 3.(x1, …, xn) ⊔ (y1, …, yn) = (x1 ⊔1 y1, …, xn ⊔n yn) 4.(x1, …, xn) ⊓ (y1, …, yn) = (x1 ⊓1 y1, …, xn ⊓n yn) Product Lattice仍是Lattice，若每个子格为全格，那么乘积也是全格 上界与下界 前提 给定偏序集(P, ⊑)及其子集S，满足S ⊆ P，则有： 上界（不唯一） 若∀x ∈ S, x ⊑ u,那么u ∈ P是子集S的上界 下界（不唯一） 若∀x ∈ S, l ⊑ x,那么l ∈ P是子集S的下界 最小上界⊔S(lub) 最大下界⊓S(glb) 特点 不是每个偏序都有lub和glb 但是如果一个偏序有lub和glb，那么它就是唯一的","categories":[{"name":"偏序","slug":"偏序","permalink":"https://lwy0518.github.io/categories/%E5%81%8F%E5%BA%8F/"}],"tags":[{"name":"偏序","slug":"偏序","permalink":"https://lwy0518.github.io/tags/%E5%81%8F%E5%BA%8F/"},{"name":"Lattice","slug":"Lattice","permalink":"https://lwy0518.github.io/tags/Lattice/"}],"author":"lwy"},{"title":"gcc中的SSA化算法","slug":"gcc中的SSA算法","date":"2021-12-26T07:44:24.000Z","updated":"2021-12-27T02:35:49.633Z","comments":true,"path":"2021/12/26/gcc中的SSA算法/","link":"","permalink":"https://lwy0518.github.io/2021/12/26/gcc%E4%B8%AD%E7%9A%84SSA%E7%AE%97%E6%B3%95/","excerpt":"SSA化算法过程 gcc中SSA化的算法描述 计算当前函数的支配结点边界 遍历并记录函数每条指令中出现的变量的defs/uses信息 为每个变量计算phi函数的插入点 按照支配树的DFS遍历重写每个bb的每条指令并将整个函数SSA化 gcc中ssa化的整体流程 pass_build_ssa 函数指令序列的def/use分析 为每个变量插入phi函数 指令重写(SSA化)","text":"SSA化算法过程 gcc中SSA化的算法描述 计算当前函数的支配结点边界 遍历并记录函数每条指令中出现的变量的defs/uses信息 为每个变量计算phi函数的插入点 按照支配树的DFS遍历重写每个bb的每条指令并将整个函数SSA化 gcc中ssa化的整体流程 pass_build_ssa 函数指令序列的def/use分析 为每个变量插入phi函数 指令重写(SSA化) SSA化算法过程gcc中SSA化的算法描述SSA化的流程可以简化为: (1)对所有变量插入必要的phi函数 (2)依次重写各个变量的定值/使用(转化为SSA格式) 而具体到gcc中则大体分为4个步骤: 计算当前函数的支配结点边界​ 按照迭代的必经结点边界算法, 要想确定phi函数插入的位置,必须要先根据函数的CFG确定函数的支配结点边界(支配结点边界的定义和算法见[2]), 在gcc中则是 1) 先通过calculate_dominance_info计算当前函数的支配结点信息 2) 再通过compute_dominance_frontiers计算当前函数的支配结点边界信息 遍历并记录函数每条指令中出现的变量的defs/uses信息​ 此步主要是收集函数每条指令中出现的变量的defs/uses信息,这些信息保存在标量的bitmap中, 故可以按照任意的顺序遍历指令,而在gcc中则是采用基于支配树的深度优先遍历(DFS)顺序遍历各个基本块(bb)中的一条条指令 为每个变量计算phi函数的插入点​ 1)中已经计算出了每个bb的支配结点边界信息；2)中计算出了每个变量的defs/uses信息, 按照迭代的必经结点边界算法, 此变量每一个def出现的结点的必经结点边界结点均需要插入一个phi函数, 插入后的phi函数作为此变量的一个新定值(def)点参与迭代计算. 1针对当前函数中的每个变量均需要通过此算法计算出其需要插入phi函数的结点信息,并在对应结点为每个变量分别插入phi函数 按照支配树的DFS遍历重写每个bb的每条指令并将整个函数SSA化​ 这里和步骤2)不同, SSA化的过程必须按照支配树的深度优先算法遍历结点, 123456789(1)对于每个结点顺序需遍历所有语句,对于每条语句: A.若发现一个操作数中涉及变量使用(use)时,需要将此操作数改为对此变量在DFS上最新定义(SSA_NAME)的使用 B.若发现一个操作数中涉及变量定值(def)时,需要为此变量新创建一个SSA_NAME作为此变量的最新定义, 并将此此操作数改为新创建的SSA_NAME (2) 语句处理完毕后续为此结点的每个后继结点的所有phi函数确定一个参数(phi函数的第x个参数来自其第x个前驱结点) phi函数对应原始变量在4.4)-1)-2)中的最新定值(def)则为phi函数的第x个参数,代表运行时来若控制流来自第x个前驱,则当前参数x的定值应来自哪个SSA_NAME gcc中ssa化的整体流程pass_build_ssa​ 在gcc中 pass_build_ssa 负责对一个函数进行首次ssa转化,而 update_ssa则负责对转化后的ssa的更新, pass_build_ssa大体流程如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960/* pass_build_ssa负责对函数cfun的SSA化,整个SSA化可以分为4步: 1.计算当前函数的支配结点边界信息 //compute_dominance_frontiers (dfs); 2.以支配树的DFS遍历为顺序, 标记每条指令中的def/use信息到各个全局变量 //mark_def_dom_walker (CDI_DOMINATORS).walk (fun-&gt;cfg-&gt;x_entry_block_ptr); 3.根据1中的支配节点边界信息和2中统计的每个变量的def/use信息, 确认每个 变量需要在哪些bb中插入phi函数,并为每个变量插入对应个数的phi函数 //insert_phi_nodes (dfs); 4.以支配树的DFS遍历为顺序,遍历所有bb并重写每条指令中的所有use/def操作数(SSA化) //rewrite_blocks 1) 在遍历到每个bb时执行: 1) 将bb中所有phi函数的返回值,写入到其对应变量的当前定义中(currdef) 2) 遍历bb中所有指令序列,并重写其中的变量: 1) 当发现一个变量的use时,用其currdef这个SSA_NAME替换指令中原有的use操作数 2) 当发现一个变量的def时,为其新创建一个SSA_NAME替换指令中原有的def操作数,并将此SSA_NAME记录到此变量的currdef中,以及入栈 3) 重写此bb所有后续bb中每个phi函数的第i个参数,i为当前bb在其后续bb的前驱bbs中的编号,phi函数的第i个参数被修改为其对应变量var在当前bb中最后的def(currdef) 2) 在每个bb的所有sub bb都遍历结束后: 1) 将4-1-2-2)中栈中保存的所有def都恢复到其对应变量的currdef中, 以保证当前bb分析完毕其父bb中的变量定义不变,继续rename其兄弟bb时才能保证正确*/unsigned int pass_build_ssa::execute (function *fun)&#123; bitmap_head *dfs; basic_block bb; init_ssa_operands (fun); /* 此函数主要为当前函数分配了virtual use/def操作的虚拟操作数vop */ init_ssa_renamer (); /* 标记当前函数尚未处于SSA格式, 初始化记录此函数中每个变量def/use的 var_infos 数组 */ /* 根据此函数基本块的数目分配一个一维的bitmap并初始化, 后续use/def分析中会在此bitmap中标记出现了use/def的bb(大部分都会出现) */ interesting_blocks = sbitmap_alloc (last_basic_block_for_fn (fun)); bitmap_clear (interesting_blocks); /* 根据此函数基本块数目,分配并初始化一个二维的bitmap矩阵(dfs[x][x]),后续此bitmap用来记录此函数中每个bb的支配结点边界信息 */ dfs = XNEWVEC (bitmap_head, last_basic_block_for_fn (fun)); FOR_EACH_BB_FN (bb, fun) bitmap_initialize (&amp;dfs[bb-&gt;index], &amp;bitmap_default_obstack); /* step1:根据此函数(cfun)的CFG寄存器支配树和每个bb的支配结点边界[2], 支配节点边界是判断是否需要插入phi函数的关键,最终dfs中: * dfs[x]记录bb x的支配节点边界 * dfs[x][y] = true; 代表y是x节点的一个支配节点边界节点 */ calculate_dominance_info (CDI_DOMINATORS); /* 这里先根据CFG计算此函数的支配树,支配树以一个个支配结点结构体保存在各个 bb-&gt;doms[0]中 */ compute_dominance_frontiers (dfs); /* 根据支配树信息(bbs-&gt;doms), 计算所有bb的支配结点边界信息并记录到二维bitmap dfs中 */ /* step2:按照DFS算法遍历此函数的支配树中每个结点(bbs-&gt;doms),对于每个结点都要遍历其整个指令序列(bb-&gt;gimple_df-&gt;seqs)中的 每一条语句(stmt),并将每条语句的def/use信息更新到 stmt-&gt;vuse/vdef/use_ops的同时,也更新到全局的var_infos/interest_blocks (针对整个函数),以及m_kills(针对当前bb)中 */ mark_def_dom_walker (CDI_DOMINATORS).walk (fun-&gt;cfg-&gt;x_entry_block_ptr); /* step3: 根据支配结点边界信息和每个变量的def/use信息,为每个变量在必要的bb中插入此变量的phi函数, 一个bb中所有插入的phi函数均记录在其bb-&gt;gimple_df-&gt;phi_nodes链表中, 按照算法, 某个变量var若在某个bb中出现了def,则此bb的支配结点边界中所有的bbs都要插入var的phi函数 需要注意的是:此时插入的phi函数只有返回值结点(为var新生成的SSA_NAME),其参数列表为空,只有在其前驱结点重写后phi函数的参数才能得以填充 */ insert_phi_nodes (dfs); /* step4: 按照DFS算法再次遍历函数的支配树,并重写每个bb中的每条指令stmt(也就是SSA化), stmt中的每个use要改为对齐currdef(SSA_NAME)的use, 每个def都要新建一个新的SSA_NAME; 对于一个bb的SSA化又分为三步: 1. 将此bb中所有phi函数的返回值设置为其对应变量的currdef 2. 遍历此bb中所有stmt, 将其中所有use的操作数改为其currdef; 若碰到def则为其原始变量var生成一个新的SSA_NAME,将def的操作数和currdef替换为新的SSA_NAME 3. 遍历此bb在函数CFG中所有的后继bb, 填充后继bb中所有phi指令的一个参数(第x个参数,x为此bb在其后继bb的所有前驱结点中的编号) */ rewrite_blocks (ENTRY_BLOCK_PTR_FOR_FN (fun), REWRITE_ALL); ...... return 0;&#125; 函数指令序列的def/use分析​ 要分析当前函数中所有变量的def/use信息,这是通过函数mark_def_dom_walker::walk()实现的: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768class mark_def_dom_walker : public dom_walker /* 没有单独实现 walk函数,继承父类walk函数 */&#123;public: mark_def_dom_walker (cdi_direction direction); ~mark_def_dom_walker (); virtual edge before_dom_children (basic_block);private: bitmap m_kills; /* 此bitmap可以看做是一个以变量UID为下标的一维数组, m_kills[x] = 1;则代表UID为x的变量在当前分析的bb中出现了kill def */&#125;; class dom_walker&#123; ...... void walk (basic_block); ......&#125; /* 在此函数执行前,bb所在的函数必须已经计算过了支配树(calculate_dominance_info),此时计算结果已经保存到各个bb-&gt;doms中了, 而此函数则通过深度优先遍历算法(DFS)遍历从bb开始的整个支配树的所有结点,且: * 在刚遍历到某个结点时,为当前结点调用before_dom_children(basic_block);回调 - 若此回调返回STOP,则其所有子节点不必再遍历 - 若此回调返回非STOP,则按照DFS继续遍历其子结点 * 在某个结点(及其子节点)遍历完毕后, 为当前结点调用after_dom_children(basic_block);回调*/void dom_walker::walk (basic_block bb)&#123; int sp = 0; basic_block dest; basic_block *worklist = XNEWVEC (basic_block, n_basic_blocks_for_fn (cfun) * 2); /* 为后续递归遍历分配临时的结点栈 */ ...... while (true) &#123; /* 只遍历有前驱的bb或函数出入口bb */ if (EDGE_COUNT (bb-&gt;preds) &gt; 0 || bb == ENTRY_BLOCK_PTR_FOR_FN (cfun) || bb == EXIT_BLOCK_PTR_FOR_FN (cfun)) &#123; edge taken_edge = NULL; taken_edge = before_dom_children (bb); /* 在遍历到一个结点时,先调用 before_dom_children 回调 */ worklist[sp++] = bb; /* 将当前节点放到worklist中,作为栈帧标记(NULL为分隔符),后续会先递归处理其子节点 */ worklist[sp++] = NULL; if (taken_edge != STOP) /* 若回调返回的非 STOP(-1) */ &#123; int saved_sp = sp; /* 遍历结点bb在支配树中的所有子节点,支配树信息在walk之前应该已经计算出(calculate_dominance_info),并记录在各个bb-&gt;doms中 */ for (dest = first_dom_son (m_dom_direction, bb); dest; dest = next_dom_son (m_dom_direction, dest)) worklist[sp++] = dest; /* 在栈中记录当前bb的所有要遍历的支配树中的子结点 */ if (sp - saved_sp &gt; 1 &amp;&amp; m_dom_direction == CDI_DOMINATORS &amp;&amp; m_bb_to_rpo) /* 若对支配树的 DFS遍历有顺序要求,则将bb的子节点排序以确保后续的遍历顺序 */ sort_bbs_postorder (&amp;worklist[saved_sp], sp - saved_sp); &#125; &#125; while (sp &gt; 0 &amp;&amp; !worklist[sp - 1]) /* 若当前bb没有子结点,或所有子节点都处理完毕,则为当前结点调用处理完毕后的回调, while循环负责处理多级结点返回 */ &#123; --sp; /* 忽略前面标记的NULL分隔符 */ bb = worklist[--sp]; /* 处理上一层的下一个bb */ ...... after_dom_children (bb); /* 当前结点及其子节点遍历完毕的回调函数 */ &#125; if (sp) bb = worklist[--sp]; /* 递归遍历worklist中下一个结点 */ else break; /* 整个支配树结点的DFS遍历完毕, 退出循环 */ &#125; free (worklist);&#125; ​ 由上可知, mark_def_dom_walker (CDI_DOMINATORS).walk (fun-&gt;cfg-&gt;x_entry_block_ptr); 实际上是通过其父类的walk函数从当前函数的入口bb开始根据DFS算法遍历了此函数的支配树,并对每个bb调用了回调函数mark_def_dom_walker::before_dom_children,此函数定义如下: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950edge mark_def_dom_walker::before_dom_children (basic_block bb)&#123; gimple_stmt_iterator gsi; bitmap_clear (m_kills); /* 重新清空记录当前bb中kill defs的数组 */ for (gsi = gsi_start_bb (bb); !gsi_end_p (gsi); gsi_next (&amp;gsi)) /* 遍历当前bb中所有gimple语句 */ /* 分析每条语句中的def/use信息,结果更新到stmt-&gt;vuse/vdef/use_ops的同时也 将统计信息更新到全局变量var_infos,interesting_blocks,以及参数m_kills中 */ mark_def_sites (bb, gsi_stmt (gsi), m_kills); return NULL;&#125; static void mark_def_sites (basic_block bb, gimple *stmt, bitmap kills)&#123; tree def; use_operand_p use_p; ssa_op_iter iter; update_stmt (stmt); /* 分析stmt中的 virutal use/def, real use信息,并将其更新到当前语句 stmt-&gt;vuse/vdef/use_ops中 */ ...... set_register_defs (stmt, false); /* 默认标记当前stmt中不存在操作数的def/use操作 */ set_rewrite_uses (stmt, false); ...... FOR_EACH_SSA_USE_OPERAND (use_p, stmt, iter, SSA_OP_ALL_USES) /* 遍历此stmt中的所有uses的操作数 */ &#123; tree sym = USE_FROM_PTR (use_p); /* 获取当前处理的操作数中的变量树节点信息 */ ...... /* 在当前bb的每条语句分析过程中(见下面的循环)如果发现了某变量的def,那么此def对于当前bb来说就是个kill def, 而如果分析到一个变量的use前还没有在当前bb中发现其kill def,则说明此变量的值来自其前驱bb, 那么此时就要 标记此变量在当前bb中出现了传播使用(set_livein_block) */ if (!bitmap_bit_p (kills, DECL_UID (sym))) /* 若此变量在当前bb中未出现kill def */ set_livein_block (sym, bb); /* 在变量的全局var_info-&gt;def_blocks-&gt;livein_blocks中标记,变量sym在基本块bb中为传播使用 */ set_rewrite_uses (stmt, true); /* 标记当前语句stmt中有需要被重写的use操作数 */ &#125; FOR_EACH_SSA_TREE_OPERAND (def, stmt, iter, SSA_OP_ALL_DEFS) /* 动态分析当前stmt的所有defs, 并遍历所有被def的变量 */ &#123; ...... set_def_block (def, bb, false); /* 在当前变量的 var_info-&gt;def_blocks-&gt;def_blocks 中标记在基本块bb中出现了此变量的def */ bitmap_set_bit (kills, DECL_UID (def)); /* 在per bb的kills数组中标记当前bb中出现了变量def的 kill def */ set_register_defs (stmt, true); /* 在当前语句stmt中标记其中出现了某操作数的def操作 */ &#125; /* 当当前分析的bb中任何一条语句(stmt)中出现了操作数的use/def操作,当前bb就要被标记为interesting. 除了特别简单的bb,基本上大部分bb都会标记到interesting_blocks中 */ if (rewrite_uses_p (stmt) || register_defs_p (stmt)) bitmap_set_bit (interesting_blocks, bb-&gt;index);&#125; 为每个变量插入phi函数​ 分析完def/use信息后,则需要为当前函数的每个变量在需要的位置(bb)处插入phi函数,此过程是在函数 insert_phi_nodes中实现的： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118/* 此函数负责为当前函数中所有变量在需要插入phi函数的bb中插入phi函数， phi函数全部记录在每个bb-&gt;gimple_df-&gt;phi_nodes中 需要注意的是此时phi函数的参数尚未填充,只有返回值填充了(其对应变量派生的SSA_NAME)*/static void insert_phi_nodes (bitmap_head *dfs)&#123; var_info *info; ...... /* var_infos[]中记录了当前函数所有变量(local_decls)在整个函数中的def/use信息, 而在def/use分析中简单的排除了一些不需要插入phi函数的变量(need_phi_state = NEED_PHI_STATE_NO的变量, 这样的变量在整个函数中只存在一个def,且其所有use点所在的bb都被def所在的bb支配),而vars数组中最终只记录了那些可能需要插入phi函数的变量做二次分析和处理 */ auto_vec&lt;var_info *&gt; vars (var_infos-&gt;elements ()); FOR_EACH_HASH_TABLE_ELEMENT (*var_infos, info, var_info_p, hi) if (info-&gt;info.need_phi_state != NEED_PHI_STATE_NO) vars.quick_push (info); vars.qsort (insert_phi_nodes_compare_var_infos); /* 根据变量的UID排序 */ FOR_EACH_VEC_ELT (vars, i, info) /* 遍历当前函数中每个可能要插入phi结点的变量(info为迭代器) */ &#123; /* * info-&gt;info.def_blocks.def_blocks 记录info-&gt;var这个变量在各个bb中的def信息(bitmap) * dtf记录整个函数所有bb的支配结点边界信息 此函数根据二者计算出需要为当前变量var插入phi函数的所有bb的信息,返回的idf同样是一个bitmap,若idf[i]-1,则代表在编号为i的bb中需要为变量info-&gt;var插入phi函数 */ bitmap idf = compute_idf (info-&gt;info.def_blocks.def_blocks, dfs); /* 根据idf这个bitmap, 向其对应的bb中为变量info-&gt;var创建一个gphi指令,并将此指令添加到 bb-&gt;gimple_df-&gt;phi_nodes中, ifd是标准算法算出的phi函数插入点,而此函数在创建前还会再次裁剪 idf bitmap(对于变量kill def且不存在livein use的bb,无需插入phi函数) */ insert_phi_nodes_for (info-&gt;var, idf, false); BITMAP_FREE (idf); &#125;&#125; /* 此函数负责根据变量var的def信息(def_blocks)和整个函数所有bb的支配结点边界信息,(dfs) 计算出需要为此函数插入phi函数的bb信息(bitmap phi_insertion_points)并返回此bitmap phi函数的算法是: 1) 当前变量x所有的def点(bb)的支配结点边界中所有结点都需要插入phi函数 2) 插入的phi函数相当于对变量x的隐式def,故插入了phi函数的结点(bb)的支配结点边界中所有结点也都要插入phi函数 3) 针对一个变量x, 任何一个bb中只需要为其插入一个phi函数即可,无需重复插入,因为phi函数参数来自于所有前驱,一个phi函数就代表了所有可能的隐式def;*/bitmap compute_idf (bitmap def_blocks, bitmap_head *dfs)&#123; bitmap_iterator bi; unsigned bb_index, i; bitmap phi_insertion_points; auto_vec&lt;int&gt; work_stack (2 * n_basic_blocks_for_fn (cfun)); /* 此bitmap为函数的返回值, 其是一个一维数组,下标为bb在当前函数的索引号， phi_insertion_points[i] = 1;则代表当前bb中需要为变量x插入phi函数 */ phi_insertion_points = BITMAP_ALLOC (NULL); /* 按照算法, phi函数需要插入到变量 x所有def点所在bb的支配结点边界结点中, 这里首先将所有出现变量x def点的bb加入到队列中 */ EXECUTE_IF_SET_IN_BITMAP (def_blocks, 0, bb_index, bi) work_stack.quick_push (bb_index); while (work_stack.length () &gt; 0) &#123; bb_index = work_stack.pop (); /* 获取下一个存在变量x def的bb的编号 */ /* &amp;dfs[bb_index] 记录索引号为bb_index的bb的支配结点边界信息(下标为bb索引号, dfs[bb_index][i] = 1; 则代表编号为i的bb为编号为 bb_index的bb的支配结点) 此宏展开后会依次比较 dfs[bb_index] 和phi_insertion_points 中的每一个bit,若 dfs[bb_index][i] = 1; 而phi_insertion_points[i] = 0; 则代表发现了 新的需要插入phi函数的bb(编号为i),此时会将i push到work_stack中,下一次循环后会递归遍历此bb; */ EXECUTE_IF_AND_COMPL_IN_BITMAP (&amp;dfs[bb_index], phi_insertion_points, 0, i, bi) &#123; work_stack.quick_push (i); /* 结点i因插入了φ函数,其支配结点边界结点也要加入到 phi_insertion_points中 */ bitmap_set_bit (phi_insertion_points, i); /* 标记结点i中需要插入φ函数 */ &#125; &#125; return phi_insertion_points;&#125; /* 此函数为变量var在需要插入phi函数的bb中插入gphi指令(包括创建,派生var的一个SSA_NAME作为gphi返回值,并将gphi插入到bb-&gt;gimple_df-&gt;phi_nodes指令序列中) 在插入前会尝试删除一些不需要插入phi函数的点(如果变量var在某个bb中不存在liven_use,且存在kill_def,则此bb无需插入phi函数)*/static void insert_phi_nodes_for (tree var, bitmap phi_insertion_points, bool update_p)&#123; unsigned bb_index; edge e; gphi *phi; basic_block bb; bitmap_iterator bi; def_blocks *def_map = find_def_blocks_for (var); /* 此结构体中存着变量var的多个bitmap,包括 kill def/livein use */ ...... /* def_blocks和 livein_blocks都是在 各个bb的mark_def_sites中分析出的: * def_blocks[i] = 1;代表变量var在编号为i的bb中出现了kill def; * livein_blocks[i] = 1; 代表变量var在编号为i的bb中出现了传播使用(也就是第一次访问是use,而不是def) 而在一个bb中,如果一个变量没有出现livein,且存在kill def,那么这个bb中是不需要插入phi函数的,简单说就是:在一个bb的顺序指令执行过程中, 一个变量先被赋值然后才被使用,那么在SSA化时其前驱bb对此变量的def就不必考虑了(因为没有人用), 但如果变量在此bb中没有def则必须插入phi函数, 否则会影响到此bb后续bb中var的定值. 这里就是从phi_insertion_points中去除了livein_use,且有kill def的bb,这些bb无需插入phi函数 */ prune_unused_phi_nodes (phi_insertion_points, def_map-&gt;def_blocks, def_map-&gt;livein_blocks); /* phi_insertion_points 中剩余的结点均需要为变量var插入phi函数,这里遍历其中每个bb */ EXECUTE_IF_SET_IN_BITMAP (phi_insertion_points, 0, bb_index, bi) &#123; bb = BASIC_BLOCK_FOR_FN (cfun, bb_index); /* 根据bb_index获取bb的basic_block结构体 */ if (update_p) mark_block_for_update (bb); if (TREE_CODE (var) == SSA_NAME) &#123; /* SSA_NAME 是在 update_ssa中用到的,先pass */ ...... &#125; else &#123; /* 正常变量是走这里 */ /* 创建一个gphi指令,为变量var生成一个新的SSA_NAME设置为此gphi的返回值结点(所以phi函数的返回值SSA_NAME的version编号都较小), gphi指令的所有参数都暂不填充(因为所有的指令尚未SSA化,无法填充), 并将新生成的gphi指令链接到当前bb-&gt;gimple_df-&gt;phi_nodes指令序列的末尾 */ phi = create_phi_node (var, bb); ...... &#125; set_register_defs (phi, true); /* 标记当前gphi语句中存在def操作(因为其返回值结点被def了) */ mark_phi_for_rewrite (bb, phi); &#125;&#125; 指令重写(SSA化)​ phi函数插入完毕后,需要对整个函数所有bb中的所有指令序列中所有的def/use变量进行重写,此过程是在函数rewrite_blocks 中完成的： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174static void rewrite_blocks (basic_block entry, enum rewrite_mode what)&#123; ...... if (what == REWRITE_ALL) /* 按照DFS遍历当前函数的支配树,并在: * 遍历到某个bb时执行回调 rewrite_dom_walker::before_dom_children * 遍历完成某个bb(及其所有sub bb)后执行回调 rewrite_dom_walker::after_dom_children */ rewrite_dom_walker (CDI_DOMINATORS).walk (entry); /* pass_build_ssa时走这里 */ else if (what == REWRITE_UPDATE) rewrite_update_dom_walker (CDI_DOMINATORS).walk (entry); else gcc_unreachable (); ......&#125; struct def_blocks&#123; bitmap def_blocks; /* 记录当前变量在哪些bb中出现了kill def */ bitmap phi_blocks; bitmap livein_blocks; /* 记录当前变量在哪些bb中出现了livein use */&#125;; struct common_info&#123; ENUM_BITFIELD (need_phi_state) need_phi_state : 2; /* 记录def/use分析中简单的判断结果,即当前变量是否不需要插入phi函数 */ tree current_def; /* 记录此变量在rewrite_stmt中当前的定义(通常是其一个SSA_NAME) */ struct def_blocks def_blocks; /* 记录此变量在所有bb中的kill def/livein use 信息 */&#125;; struct var_info&#123; tree var; /* 此var_info中记录了哪个变量的信息 */ common_info info; /* 记录此变量的def/use,currdef等相关信息 */ &#125;; /* 此函数负责在DFS遍历到支配树中每个结点bb时,将其中的所有stmt SSA化, SSA化的流程分为三步: 1. 将此bb中所有phi函数的返回值设置为其对应变量的currdef 2. 遍历此bb中所有stmt, 将其中所有use的操作数改为其currdef; 若碰到def则为其原始变量var生成一个新的SSA_NAME,将def的操作数和currdef替换为新的SSA_NAME 3. 遍历此bb在函数CFG中所有的后继bb, 填充后继bb中所有phi指令的一个参数(第x个参数,x为此bb在其后继bb的所有前驱结点中的编号)*/edge rewrite_dom_walker::before_dom_children (basic_block bb)&#123; ...... block_defs_stack.safe_push (NULL_TREE); /* 在stack中做一个标记,代表当前开始处理一个新的bb */ /* 对于一个变量x来说,其phi函数的作用就是在SSA化的过程中为phi函数所在bb整合此变量在其各个前驱bb中的定义, 故在SSA化的重写阶段,若一个变量在某个bb中有phi函数,那么phi函数的返回值(x的一个SSA_NAME,见insert_phi_nodes)会作为分析此bb时x的最新定义. 这里是将当前bb的所有phi函数的返回值,设置为其对应变量的最新定义(变量的var_info.currdef) */ for (gphi_iterator gsi = gsi_start_phis (bb); !gsi_end_p (gsi); gsi_next (&amp;gsi)) &#123; /* 获取gphi指令的返回值结点,其必为一个SSA_NAME结点,见phi函数的创建过程 pass_build_ssa =&gt; insert_phi_nodes =&gt; insert_phi_nodes_for =&gt; create_phi_node */ tree result = gimple_phi_result (gsi_stmt (gsi)); /* 获取此phi函数返回值结点 */ /* 将返回值结点设置为其原始变量的currdef, 如: 若当result 为SSA_NAME x_1, 则 SSA_NAME_VAR (result)为变量x,这里设置 x的var_info.curredef = (tree)x_1; */ register_new_def (result, SSA_NAME_VAR (result)); &#125; if (bitmap_bit_p (interesting_blocks, bb-&gt;index)) /* 若当前bb在前面def/use分析中发现其中至少存在一个def/use */ /* 遍历当前bb中的每一条语句,并修改每条语句中需要被重写的操作数，注意这里遍历的是bb-&gt;gimple_df-&gt;seqs, 而不是phi_nodes */ for (gimple_stmt_iterator gsi = gsi_start_bb (bb); !gsi_end_p (gsi); gsi_next (&amp;gsi)) rewrite_stmt (&amp;gsi); /* 此函数负责对一条指令(stmt)进行重写 */ /* 当前bb重写完毕(SSA化完毕),则所有的变量都已经变为其SSA形式了,此时需要为其所有后继结点填充所有phi函数的第i个参数, i为此bb在其后继的前驱结点中的编号 */ rewrite_add_phi_arguments (bb); return NULL;&#125; /* 此函数负责重写si-&gt;ptr这条语句(stmt)中的所有def/use,将此stmt SSA化, 其处理顺序是先处理use后处理def,这也符合正常一条指令执行的逻辑,stmt中: * 发现所有对原始变量var的use的操作数指针,都会被改为(指向)对其currdef这个SSA_NAME结点 * 发现所有对原始变量var的def,都会先为变量var新生成一个SSA_NAME,并将def操作数的指针改为(指向)新SSA_NAME结点,并将新的SSA_NAME更新到变量var的currdef*/static void rewrite_stmt (gimple_stmt_iterator *si)&#123; gimple *stmt = gsi_stmt (*si); /* 若当前语句中没有需要被重写的use/def,则直接返回 */ if (!rewrite_uses_p (stmt) &amp;&amp; !register_defs_p (stmt)) return; if (rewrite_uses_p (stmt)) /* 1.若当前语句中存在需要被重写的use operands,则先重写uses所有的uses操作数 */ &#123; ...... /* 遍历当前stmt的real use链表(stmt-&gt;use_ops),其中记录了当前stmt SSA化时需要被修改的USE操作数, 并将其修改为对应变量的当前SSA_NAME定义 如 y = x; 若此指令解析前x的当前定义为x_1,则这里将指令修改为 y = x_1; */ FOR_EACH_SSA_USE_OPERAND (use_p, stmt, iter, SSA_OP_ALL_USES) &#123; /* use_p-&gt;use 指向此stmt的一个操作数的内存,这里先获取其原始操作数var(即 var = *use_p-&gt;use) */ tree var = USE_FROM_PTR (use_p); ...... /* 修改此操作数为变量var的当前定义(currdef), 即 *use_p-&gt;use = var_1; (若currdef为var_1) */ SET_USE (use_p, get_reaching_def (var)); &#125; &#125; if (register_defs_p (stmt)) /* 2. 若当前语句中存在需要被重写的def operands(见mark_def_sites),则重写所有的defs操作数 */ FOR_EACH_SSA_DEF_OPERAND (def_p, stmt, iter, SSA_OP_ALL_DEFS) &#123; tree var = DEF_FROM_PTR (def_p); /* 从stmt中的def操作数中读取当前被def的变量的树节点 */ tree name; ...... if (TREE_CODE (var) == SSA_NAME) continue; /* 忽略SSA_NAME */ gcc_checking_assert (DECL_P (var)); ...... name = make_ssa_name (var, stmt); /* 为变量var新的def点重新分配一个var的SSA_NAME */ SET_DEF (def_p, name); /* 将stmt某操作数中的变量var修改为其SSA_NAME,将定义转化为静态单赋值形式 */ /* 在支配树的DFS遍历中, 变量var的当前定义此时已经变为了新生成的SSA_NAME name, 将其更新到变量var的currdef中,后续再出现的use则使用此新的def, 需要注意的是这里,这里会在全局block_defs_stack中保存所有旧的def,在rewrite_dom_walker::after_dom_children会恢复已有修改, 因为 在支配树的DFS遍历中若有 A=&gt;B, A=&gt;C; 那么分析B时产生的def只作用于B以及其所有sub bb, 而当回到A重新遍历C时要重新使用A中的def继续分析, 所以这里会有一个入栈操作.after_dom_children中完成出栈操作 */ register_new_def (DEF_FROM_PTR (def_p), var); ...... &#125;&#125; /* 在一个bb及其所有sub bb处理完成后,要恢复此bb中的所有currdef,恢复后才可以继续遍历此bb的兄弟bb,此函数则完成currdef的恢复操作 */void rewrite_dom_walker::after_dom_children (basic_block bb ATTRIBUTE_UNUSED)&#123; while (block_defs_stack.length () &gt; 0) /* 遍历def栈中的所有内容, 其插入点是上面的register_new_def函数 */ &#123; tree tmp = block_defs_stack.pop (); /* 获取stack中一个要恢复的SSA_NAME */ tree saved_def, var; if (tmp == NULL_TREE) break; /* 遍历当NULL_TREE代表当前bb之前的所有入栈处理完毕,NULL_TREE在栈中作为分隔符分隔各个bb的栈信息 */ if (TREE_CODE (tmp) == SSA_NAME) &#123; /* 大多数情况下之前push进来的结点为某个变量的SSA_NAME结点 */ saved_def = tmp; /* 当前需要恢复的SSA_NAME */ var = SSA_NAME_VAR (saved_def); /* 获取SSA_NAME的原始变量 */ ...... &#125; else &#123; /* 非SSA_NAME则说明push到原始变量了,说明在当前bb的父节点之前没有变量var的def出现 */ saved_def = NULL; /* 没有def出现时标记saved_def为空 */ var = tmp; /* tmo即为原始变量 */ &#125; /* var为原始变量,先找到其var_info结构体,然后恢复其之前定义为 saved_def */ get_common_info (var)-&gt;current_def = saved_def; &#125;&#125; /* 此函数负责遍历当前bb在函数CFG中的所有后继bb, 遍历每个后继bb中的每一条phi指令,其目的是为了填充所有bb中所有phi函数的一个参数, 后继bb中所有phi函数的参数都来自其前驱bb,在其前驱bb SSA化后要立即为其所有后续bb添加SSA化后的参数*/static void rewrite_add_phi_arguments (basic_block bb)&#123; edge e; edge_iterator ei; FOR_EACH_EDGE (e, ei, bb-&gt;succs) /* 遍历当前bb的所有直接后继bb,这里遍历的是边 */ &#123; gphi *phi; gphi_iterator gsi; for (gsi = gsi_start_phis (e-&gt;dest); !gsi_end_p (gsi); gsi_next (&amp;gsi)) /* 遍历每个后继bb中的所有phi语句 */ &#123; phi = gsi.phi (); res = gimple_phi_result (phi); /* 获取phi函数的返回值节点, 也就是此gphi语句中最终def的那个 SSA_NAME */ /* SSA_NAME_VAR (res))获取ssa name 对应的var节点, 而get_reaching_def 则获取var变量当前最新的def是哪个变量, 如res可能是var_1 = φ(,...) 中的var_1(SSA_NAME),而返回的currdef是var的最新定义(可能是var_3,也是个SSA_NAME) */ currdef = get_reaching_def (SSA_NAME_VAR (res)); ...... /* 将currdef记录到 phi函数的第x个参数中(phi.arg[x].def),并增加currdef这个SSA_NAME的use链表(将phi.arg[x].imm_use 链接到currdef.imm_use使用链中),这里的x是 e这条边在e-&gt;dest结点中的前驱边编号(当前bb在其某后继结点中的前驱结点编号) */ add_phi_arg (phi, currdef, e, loc); &#125; &#125;&#125; SSA基本概念及原理参考文章 程序分析之中间表示 gcc中的支配树 原文链接","categories":[{"name":"SSA","slug":"SSA","permalink":"https://lwy0518.github.io/categories/SSA/"}],"tags":[{"name":"SSA","slug":"SSA","permalink":"https://lwy0518.github.io/tags/SSA/"},{"name":"gcc","slug":"gcc","permalink":"https://lwy0518.github.io/tags/gcc/"},{"name":"算法","slug":"算法","permalink":"https://lwy0518.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"编译原理","slug":"编译原理","permalink":"https://lwy0518.github.io/tags/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/"}],"author":"lwy"},{"title":"Hexo NexT 主题更新","slug":"Hexo-NexT-主题更新","date":"2021-12-22T02:32:43.000Z","updated":"2021-12-22T02:59:01.322Z","comments":true,"path":"2021/12/22/Hexo-NexT-主题更新/","link":"","permalink":"https://lwy0518.github.io/2021/12/22/Hexo-NexT-%E4%B8%BB%E9%A2%98%E6%9B%B4%E6%96%B0/","excerpt":"更新Next主题12$ rm -rf ./themes/next$ cnpm install hexo-theme-next 安装第三方插件模块安装1$ cnpm install @next-theme/plugins 配置1$ vim _config.next.yml 复制以下代码到_config.next.yml 12vendors: plugins: local","text":"更新Next主题12$ rm -rf ./themes/next$ cnpm install hexo-theme-next 安装第三方插件模块安装1$ cnpm install @next-theme/plugins 配置1$ vim _config.next.yml 复制以下代码到_config.next.yml 12vendors: plugins: local","categories":[{"name":"hexo","slug":"hexo","permalink":"https://lwy0518.github.io/categories/hexo/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://lwy0518.github.io/tags/hexo/"},{"name":"Blog","slug":"Blog","permalink":"https://lwy0518.github.io/tags/Blog/"}],"author":"lwy"},{"title":"Typora快捷键","slug":"Typora快捷键","date":"2021-12-21T07:46:50.000Z","updated":"2021-12-22T03:24:17.737Z","comments":true,"path":"2021/12/21/Typora快捷键/","link":"","permalink":"https://lwy0518.github.io/2021/12/21/Typora%E5%BF%AB%E6%8D%B7%E9%94%AE/","excerpt":"Typora快捷键","text":"Typora快捷键 原文链接 源码模式1ctrl+/ 生成目录1[TOC]按回车 代码块1ctrl+alt+f 代码1ctrl+shift+` 标题1ctrl+数字 表格1ctrl+t 选中一行1ctrl+l 选中单词1ctrl+d 选中相同格式的文字1ctrl+e 跳转到文章开头1ctrl+home 跳转到文章结尾1ctrl+end 搜索1ctrl+f 替换1ctrl+h 下划线1ctrl+u 删除线1alt+shift+5 插入图片1直接拖动到指定位置即可或者ctrl+shift+i 插入链接1ctrl + k 引用1&gt; 加粗1ctrl + b 倾斜1ctrl + i 添加参考文献1[^1] # ^ 后面添加数字","categories":[{"name":"Markdown","slug":"Markdown","permalink":"https://lwy0518.github.io/categories/Markdown/"}],"tags":[{"name":"Typora","slug":"Typora","permalink":"https://lwy0518.github.io/tags/Typora/"},{"name":"Markdown","slug":"Markdown","permalink":"https://lwy0518.github.io/tags/Markdown/"}],"author":"lwy"},{"title":"污点分析","slug":"污点分析","date":"2021-12-21T07:22:46.029Z","updated":"2021-12-22T02:58:43.530Z","comments":true,"path":"2021/12/21/污点分析/","link":"","permalink":"https://lwy0518.github.io/2021/12/21/%E6%B1%A1%E7%82%B9%E5%88%86%E6%9E%90/","excerpt":"污点分析技术 基本原理 污点分析定义 识别污点源和汇聚点 污点传播分析 显示流分析 隐式流分析 无害处理 污点传播分析的关键技术 污点传播中的显示流分析 静态分析技术 动态分析技术 硬件 基于软件 混合型 污点传播中的隐式流分析 静态分析技术 动态分析技术","text":"污点分析技术 基本原理 污点分析定义 识别污点源和汇聚点 污点传播分析 显示流分析 隐式流分析 无害处理 污点传播分析的关键技术 污点传播中的显示流分析 静态分析技术 动态分析技术 硬件 基于软件 混合型 污点传播中的隐式流分析 静态分析技术 动态分析技术 污点分析方法实现实例分析 静态污点分析技术 基于数据流的污点分析 基于依赖关系的污点分析 静态污点分析实例分析 动态污点分析技术 动态污点分析的方法实现 污点数据标记 污点动态跟踪 污点误用检查 实例分析 污点分析在实际应用中的关键技术 检测智能手机隐私泄露 静态污点分析 组件内污点传播分析 组件间污点传播分析 组件与库函数之间的污点传播分析 动态污点分析 组件内污点传播分析 组件间污点传播分析 组件与本地库函数间的污点传播 总结 参考文献 污点分析技术基本原理污点分析定义污点分析可以抽象成一个**三元组&lt;sources,sinks,sanitizers&gt;**的形式，其中，source 即污点源，代表直接引入不受信任的数据或者机密数据到系统中；sink 即污点汇聚点，代表直接产生安全敏感操作(违反数据完整性)或者泄露隐私数据到外界(违反数据保密性)；sanitizer 即无害处理，代表通过数据加密或者移除危害操作等手段使数据传播不再对软件系统的信息安全产生危害。 污点分析就是分析程序中由污点源引入的数据是否能够不经无害处理，而直接传播到污点汇聚点。如果不能，说明系统是信息流安全的；否则，说明系统产生了隐私数据泄露或危险数据操作等安全问题。 在漏洞分析中，使用污点分析技术将所感兴趣的数据(通常来自程序的外部输入，假定所有输入都是危险的)标记为污点数据，然后通过跟踪和污点数据相关的信息的流向，可以知道它们是否会影响某些关键的程序操作，进而挖掘程序漏洞。即将程序是否存在某种漏洞的问题转化为污点信息是否会被 Sink 点上的操作所使用的问题。 污点分析常常包括以下几个部分(如图 2 所示)： 识别污点信息在程序中的产生点（Source点）并对污点信息进行标记(根据所分析的系统的不同使用定制的识别策略) 污点传播分析(利用特定的规则跟踪分析污点信息在程序中的传播过程) 漏洞检测、无害处理(在一些关键的程序点（Sink点）检测关键的操作是否会受到污点信息的影响) 识别污点源和汇聚点识别污点源和污点汇聚点是污点分析的前提。目前，在不同的应用程序中识别污点源和汇聚点的方法各不相同。缺乏通用方法的原因一方面来自系统模型、编程语言之间的差异。另一方面，污点分析关注的安全漏洞类型不同，也会导致对污点源和污点汇聚点的收集方法迥异。表 1 所示为在 Web 应用程序漏洞检测中的污点源示例[^1]，它们是 Web 框架中关键对象的属性。 现有的识别污点源和汇聚点的方法可以大致分成 3 类: 使用启发式的策略进行标记,例如把来自程序外部输入的数据统称为“污点”数据,保守地认为这些数据有可能包含恶意的攻击数据(如 PHP Aspis)； 根据具体应用程序调用的 API 或者重要的数据类型,手工标记源和汇聚点(如 DroidSafe[^2])； 使用统计或机器学习技术自动地识别和标记污点源及汇聚点[^3]。 污点传播分析污点传播分析就是分析污点标记数据在程序中的传播途径.按照分析过程中关注的程序依赖关系的不同, 可以将污点传播分析分为显式流分析和隐式流分析。 显示流分析污点传播分析中的显式流分析就是分析污点标记如何随程序中变量之间的数据依赖关系传播 以图 3 所 示的程序为例,变量 a 和 b 被预定义的污点源函数 source 标记为污点源.假设 a 和 b 被赋予的污点标记分别为taint_a 和 taint_b.由于第 5 行的变量 x 直接数据依赖于变量 a,第 6 行的变量 y 直接数据依赖于变量 b,显式流分析会分别将污点标记 taint_a 和 taint_b 传播给第 5 行的变量 x 和第 6 行的变量 y.又由于 x 和 y 分别可以到达第 7 行和第 8 行的污点汇聚点(用预定义的污点汇聚点函数 sink 标识),图 3 所示的代码存在信息泄漏的问题.我们将在后面具体介绍目前污点传播分析中显式流分析面临的主要挑战和解决方法。 隐式流分析污点传播分析中的隐式流分析是分析污点标记如何随程序中变量之间的**控制依赖关系传播,**也就是分析污点标记如何从条件指令传播到其所控制的语句。 在图 4 所示的程序中,变量 X 是被污点标记的字符串类型变量,变量 Y 和变量 X 之间并没有直接或间接的数据依赖关系(显式流关系),但 X 上的污点标记可以经过控制依赖隐式地传播到 Y。 具体来说,由第 4 行的循环条件控制的外层循环顺序地取出 X 中的每一个字符,转化成整型后赋给变量 x,再由第 7 行的循环条件控制的内层循环以累加的方式将 x 的值赋给 y,最后由外层循环将 y 逐一传给 Y.最终,第 12 行的 Y 值和 X 值相同,程序存在信息泄漏问题.但是,如果不进行隐式流污点传播分析,第 12 行 的变量 Y 将不会被赋予污点标记,程序的信息泄漏问题被掩盖. 隐式流污点传播一直以来都是一个重要的问题,和显式流一样,如果不被正确处理,会使污点分析的结果不精确.由于对隐式流污点传播处理不当导致本应被标记的变量没有被标记的问题称为欠污染(under-taint)问题.相反地,由于污点标记的数量过多而导致污点变量大量扩散的问题称为过污染(over-taint)问题.目前,针对隐式流问题的研究重点是尽量减少欠污染和过污染的情况.我们将在后面具体介绍现有技术是如何解决上述问题的。 无害处理污点数据在传播的过程中可能会经过无害处理模块,无害处理模块是指污点数据经过该模块的处理后,数据本身不再携带敏感信息或者针对该数据的操作不会再对系统产生危害.换言之,带污点标记的数据在经过无害处理模块后,污点标记可以被移除.正确地使用无害处理可以降低系统中污点标记的数量,提高污点分析的效率,并且避免由于污点扩散导致的分析结果不精确的问题 在应用过程中,为了防止敏感数据被泄露(保护保密性),通常会对敏感数据进行加密处理.此时,加密库函数应该被识别成无害处理模块.这一方面是由于库函数中使用了大量的加密算法,导致攻击者很难有效地计算出密码的可能范围;另一方面是加密后的数据不再具有威胁性,继续传播污点标记没有意义。 此外,为了防止外界数据因为携带危险操作而对系统关键区域产生危害(保护完整性),通常会对输入的数据进行验证。 综上,目前对污点源、污点汇聚点以及无害处理模块的识别通常根据系统或漏洞类型使用定制的方法.由于这些方法都比较直接,本文将不再进行更深入的探讨.下一节将重点介绍污点传播中的关键技术。 总结，使用污点分析检测程序漏洞的工作原理如下图所示： 基于数据流的污点分析。在不考虑隐式信息流的情况下，可以将污点分析看做针对污点数据的数据流分析。根据污点传播规则跟踪污点信息或者标记路径上的变量污染情况，进而检查污点信息是否影响敏感操作。 基于依赖关系的污点分析。考虑隐式信息流，在分析过程中，根据程序中的语句或者指令之间的依赖关系，检查 Sink 点处敏感操作是否依赖于 Source 点处接收污点信息的操作。 污点传播分析的关键技术污点传播分析是当前污点分析领域的研究重点.与程序分析技术相结合,可以获得更加高效、精确的污点分析结果.根据分析过程中是否需要运行程序,可以将污点传播分析分为静态污点分析和动态污点分析.本节主要介绍如何使用动/静态程序分析技术来解决污点传播中的显式流分析和隐式流分析问题 显式流分析和隐式流分析是从两种不同的角度(数据流和控制流)来观察污点传播 污点传播中的显式流分析静态分析技术静态污点传播分析(简称静态污点分析)是指在不运行且不修改代码的前提下,通过分析程序变量间的数据依赖关系来检测数据能否从污点源传播到污点汇聚点. 静态污点分析的对象一般是程序的源码或中间表示.可以将对污点传播中显式流的静态分析问题转化为对程序中静态数据依赖的分析: 首先,根据程序中的函数调用关系构建调用图(call graph,简称CG); 然后,在函数内或者函数间根据不同的程序特性进行具体的数据流传播分析.常见的显式流污点传播方式包括直接赋值传播、通过函数(过程)调用传播以及通过别名(指针)传播 以图 5 所示的 Java 程序为例: 第 3 行的变量 b 为初始的污点标记变量,程序第 4 行将一个包含变量 b 的算术表达式的计算结果直接赋给变量 c.由于变量 c 和变量 b 之间具有直接的赋值关系,污点标记可直接从赋值语句右部的变量传播到左部,也就是上述 3种显式流污点传播方式中的直接赋值传播 接下来,变量 c 被作为实参传递给程序第 5 行的函数 foo,c 上的污点标记也通过函数调用传播到 foo 的形参 z,z 的污点标记又通过直接赋值传播到程序第 8 行的 x.f.由于 foo 的另外两个参数对象 x 和 y 都是对对象 a 的引用,二者之间存在别名,因此,x.f的污点标记可以通过别名传播到第 9 行的污点汇聚点,程序存在泄漏问题. 目前,利用数据流分析解决显式污点传播分析中的直接赋值传播和函数调用传播已经相当成熟,研究的重点是如何为别名传播的分析提供更精确、高效的解决方案.由于精确度越高(上下文敏感、流敏感、域敏感、对象敏感等)的程序静态分析技术往往伴随着越大的时空开销,追求全敏感且高效的别名分析难度较大.又由于静态污点传播分析关注的是从污点源到污点汇聚点之间的数据流关系,分析对象并非完整的程序,而是确定的入口和出口之间的程序片段.这就意味着可以尝试采用按需(on-demand)定制的别名分析方法来解决显式流态污点分析中的别名传播问题 动态分析技术动态污点传播分析(简称动态污点分析)是指在程序运行过程中,通过实时监控程序的污点数据在系统程序中的传播来检测数据能否从污点源传播到污点汇聚点.动态污点传播分析首先需要为污点数据扩展一个污点标记(tainted tag)的标签并将其存储在存储单元(内存、寄存器、缓存等)中,然后根据指令类型和指令操作数设计相应的传播逻辑传播污点标记 动态污点传播分析按照实现层次被分为基于硬件、基于软件以及混合型的污点传播分析这3类 1.硬件基于硬件的污点传播分析需要定制的硬件支持,一般需要在原有体系结构上为寄存器或者内存扩展一个标记位,用来存储污点标记 2.基于软件基于软件的污点传播分析通过修改程序的二进制代码来进行污点标记位的存储与传播 基于软件的污点传播的优点在于不必更改处理器等底层的硬件,并且可以支持更高的语义逻辑的安全策略(利用其更贴近源程序层次的特点),但缺点是使用插桩(instrumentation 在保证被测程序原有逻辑完整性的基础上在程序中插入一些探针)或代码重写(code rewriting)修改程序往往会给分析系统带来巨大的开销.相反地,基于硬件的污点传播分析虽然可以利用定制硬件降低开销,但通常不能支持更高的语义逻辑的安全策略,并且需要对处理器结构进行重新设计 3.混合型混合型的污点分析是对上述两类方法的折中,即,通过尽可能少的硬件结构改动以保证更高的语义逻辑的安全策略 目前,针对动态污点传播分析的研究工作关注的首要问题是如何设计有效的污点传播逻辑,以确保精确的污点传播分析 污点传播中的隐式流分析污点传播分析中的隐式流分析就是分析污点数据如何通过控制依赖进行传播,如果忽略了对隐式流污点传播的分析,则会导致欠污染的情况;如果对隐式流分析不当,那么除了欠污染之外,还可能出现过污染的情况.与显式流分析类似,隐式流分析技术同样也可以分为静态分析和动态分析两类 静态分析技术静态隐式流分析面临的核心问题是精度与效率不可兼得的问题.精确的隐式流污点传播分析需要分析每一个分支控制条件是否需要传播污点标记.路径敏感的数据流分析往往会产生路径爆炸问题,导致开销难以接受.为了降低开销,一种简单的静态传播(标记)分支语句的污点标记方法是将控制依赖于它的语句全部进行污点标记,但该方法会导致一些并不携带隐私数据的变量被标记,导致过污染情况的发生.过污染会引起污点的大量扩散,最终导致用户得到的报告中信息过多,难以使用 动态分析技术动态隐式流分析关注的首要问题是如何确定污点控制条件下需要标记的语句的范围.由于动态执行轨迹并不能反映出被执行的指令之间的控制依赖关系,目前的研究多采用离线的静态分析辅助判断动态污点传播中的隐式流标记范围.Clause等人提出,利用离线静态分析得到的控制流图节点间的后支配(post-dominate)关系来解决动态污点传播中的隐式流标记问题 例如,如图 6(a)所示,程序第 3 行的分支语句被标记为污点源,当document.cookie 的值为 abc 时,会发生污点数据泄露.根据基于后支配关系的标记算法,会对该示例第 4 行语句的指令目的地,即 x 的值进行污点标记.(ps:因为根据该分支控制下的语句的执行结果可以判定污染源document.cookie的值,造成污点数据泄露) 动态分析面临的第 2 个问题是由于部分泄漏(partially leaked)导致的漏报.部分泄漏是指污点信息通过动态未执行部分进行传播并泄漏.Vogt等人发现,只动态地标记分支条件下的语句会发生这种情况 仍以图 6(a)中的程序为例:当第 3 行的控制条件被执行时,对应的 x 会被标记.此时,x 的值为 true,而 y 值没有变化,仍然为 false.在后续执行过程中,由于第 9行的污点汇聚点不可达,而第 12 行的汇聚点可达,动态分析没有检测到污点数据泄漏.但攻击者由第 11 行 y 等于 false 的条件能够反推出程序执行了第 3 行的分支条件,程序实际上存在信息泄漏的问题.这个信息泄露是由第 6 行未被执行到的 y 的赋值语句所触发的.因此,y 应该被动态污点传播分析所标记.为了解决部分泄漏问题,Vogt等人在传统的动态污点分析基础上增加了离线的静态分析,以跟踪动态执行过程中的控制依赖关系,对污点分支控制范围内的所有赋值语句中的变量都进行标记.具体到图 6(a)所示的例子,就是第 4 行和第 6 行中的变量均会被污点标记.但是,Vogt 等人的方法仍然会产生过污染的情况. 动态分析需要解决的第 3 个问题是如何选择合适的污点标记分支进行污点传播.鉴于单纯地将所有包含污点标记的分支进行传播会导致过污染的情况,可以根据信息泄漏范围的不同,定量地设计污点标记分支的选择策略. 以图 6(b)所示的程序为例,第 2 行的变量 a 为初始的污点标记变量.第 5 行、第 7 行、第 9 行均为以 a作为源操作数的污点标记的分支.如果传播策略为只要分支指令中包含污点标记就对其进行传播,那么第 5 行、第 7 行、第 9 行将分别被传播给第 6 行、第 8 行、第 10 行,并最终传播到第 12 行的污点汇聚点.如果对这段程序进行深入分析会发现,3个分支条件所提供的信息值(所能泄露的信息范围)并不相同,分别是 a 等于 10、a大于 10 且小于或等于 13(将 w 值代入计算)以及 a 小于 10.对于 a 等于 10 的情况,攻击者可以根据第 12 行泄漏的 x 的值直接还原出污点源处 a 的值(这类分支也被称为能够保存完整信息的分支);对于 a 大于 10 且小于或等于 13 的情况,攻击者也只需要尝试 3 次就可以还原信息;而对于 a 小于 10 的情况,攻击者所获得的不确定性较大,成功还原信息的几率显著低于前两种,对该分支进行污点传播的实际意义不大. Bao等人只将严格控制依赖(strict control dependence)识别成需要污点传播的分支,其中,严格控制依赖即分支条件表达式的两端具有常数差异的分支.但是,Bao 的方法只适用于能够在编译阶段计算出常数差异的分支. 污点分析方法实现静态污点分析技术静态污点分析系统首先对程序代码进行解析，获得程序代码的中间表示，然后在中间表示的基础上对程序代码进行控制流分析等辅助分析，以获得需要的控制流图、调用图等。在辅助分析的过程中，系统可以利用污点分析规则在中间表示上识别程序中的 Source 点和 Sink 点。最后检测系统根据污点分析规则，利用静态污点分析检查程序是否存在污点类型的漏洞。 基于数据流的污点分析在基于数据流的污点分析中，常常需要一些辅助分析技术，例如别名分析、取值分析等，来提高分析精度。辅助分析和污点分析交替进行，通常沿着程序路径的方向分析污点信息的流向，检查 Source 点处程序接收的污点信息是否会影响到 Sink 点处的敏感操作。 过程内的分析中，按照一定的顺序分析过程内的每一条语句或者指令，进而分析污点信息的流向。 记录污点信息。在静态分析层面，程序变量的污染情况为主要关注对象。为记录污染信息，通常为变量添加一个污染标签。最简单的就是一个布尔型变量，表示变量是否被污染。更复杂的标签还可以记录变量的污染信息来自哪些 Source 点，甚至精确到 Source 点接收数据的哪一部分。当然也可以不使用污染标签，这时我们通过对变量进行跟踪的方式达到分析污点信息流向的目的。例如使用栈或者队列来记录被污染的变量。 程序语句的分析。在确定如何记录污染信息后，将对程序语句进行静态分析。通常我们主要关注赋值语句、控制转移语句以及过程调用语句三类。 赋值语句。 对于简单的赋值语句，形如 a = b 这样的，记录语句左端的变量和右端的变量具有相同的污染状态。程序中的常量通常认为是未污染的，如果一个变量被赋值为常量，在不考虑隐式信息流的情况下，认为变量的状态在赋值后是未污染的。 对于形如 a = b + c 这样带有二元操作的赋值语句，通常规定如果右端的操作数只要有一个是被污染的，则左端的变量是污染的（除非右端计算结果为常量）。 对于和数组元素相关的赋值，如果可以通过静态分析确定数组下标的取值或者取值范围，那么就可以精确地判断数组中哪个或哪些元素是污染的。但通常静态分析不能确定一个变量是污染的，那么就简单地认为整个数组都是污染的。 对于包含字段或者包含指针操作的赋值语句，常常需要用到指向分析的分析结果。 控制转移语句。 在分析条件控制转移语句时，首先考虑语句中的路径条件可能是包含对污点数据的限制，在实际分析中常常需要识别这种限制污点数据的条件，以判断这些限制条件是否足够包含程序不会受到攻击。如果得出路径条件的限制是足够的，那么可以将相应的变量标记为未污染的。 对于循环语句，通常规定循环变量的取值范围不能受到输入的影响。例如在语句 for (i = 1； i &lt; k； i++)&#123;&#125; 中，可以规定循环的上界 k 不能是污染的。 过程调用语句。 可以使用过程间的分析或者直接应用过程摘要进行分析。污点分析所使用的过程摘要主要描述怎样改变与该过程相关的变量的污染状态，以及对哪些变量的污染状态进行检测。这些变量可以是过程使用的参数、参数的字段或者过程的返回值等。例如在语句 flag = obj。method(str)； 中，str 是污染的，那么通过过程间的分析，将变量 obj 的字段 str 标记为污染的，而记录方法的返回值的变量 flag 标记为未污染的。 在实际的过程间分析中，可以对已经分析过的过程构建过程摘要。例如前面的语句，其过程摘要描述为：方法 method 的参数污染状态决定其接收对象的实例域 str 的污染状态，并且它的返回值是未受污染的。那么下一次分析需要时，就可以直接应用摘要进行分析。 代码的遍历。一般情况下，常常使用流敏感的方式或者路径敏感的方式进行遍历，并分析过程中的代码。如果使用流敏感的方式，可以通过对不同路径上的分析结果进行汇集，以发现程序中的数据净化规则。如果使用路径敏感的分析方式，则需要关注路径条件，如果路径条件中涉及对污染变量取值的限制，可认为路径条件对污染数据进行了净化，还可以将分析路径条件对污染数据的限制进行记录，如果在一条程序路径上，这些限制足够保证数据不会被攻击者利用，就可以将相应的变量标记为未污染的。 过程间的分析与数据流过程间分析类似，使用自底向上的分析方法，分析调用图中的每一个过程，进而对程序进行整体的分析。 基于依赖关系的污点分析在基于依赖关系的污点分析中，首先利用程序的中间表示、控制流图和过程调用图构造程序完整的或者局部的程序的依赖关系。在分析程序依赖关系后，根据污点分析规则，检测 Sink 点处敏感操作是否依赖于 Source 点。 分析程序依赖关系的过程可以看做是构建程序依赖图的过程。程序依赖图是一个有向图。它的节点是程序语句，它的有向边表示程序语句之间的依赖关系。程序依赖图的有向边常常包括数据依赖边和控制依赖边。在构建有一定规模的程序的依赖图时，需要按需地构建程序依赖关系，并且优先考虑和污点信息相关的程序代码。 静态污点分析实例分析在使用污点分析方法检测程序漏洞时，污点数据相关的程序漏洞是主要关注对象，如 SQL 注入漏洞、命令注入漏洞和跨站脚本漏洞等。 下面是一个存在 SQL 注入漏洞 ASP 程序的例子： 1234567891011121314&lt;% Set pwd = &quot;bar&quot; Set sql1 = &quot;SELECT companyname FROM &quot; &amp; Request。Cookies(&quot;hello&quot;) Set sql2 = Request。QueryString(&quot;foo&quot;) MySqlStuff pwd， sql1， sql2 Sub MySqlStuff(password， cmd1， cmd2) Set conn = Server。CreateObject(&quot;ADODB。Connection&quot;) conn。Provider = &quot;Microsoft。Jet。OLEDB。4。0&quot; conn。Open &quot;c：/webdata/foo。mdb&quot;， &quot;foo&quot;， password Set rs = conn。Execute(cmd2) Set rs = Server。CreateObject(&quot;ADODB。recordset&quot;) rs。Open cmd1， conn End Sub%&gt; 首先对这段代码表示为一种三地址码的形式，例如第 3 行可以表示为： 1234567a = &quot;SELECT companyname FROM &quot;b = &quot;hello&quot;param0 Requestparam1 bcallCookiesreturn csql1 = a &amp; c 解析完毕后，需要对程序代码进行控制流分析，这里只包含了一个调用关系（第 5 行）。 接下来，需要识别程序中的 Source 点和 Sink 点以及初始的被污染的数据。 具体的分析过程如下： 调用 Request。Cookies(“hello”) 的返回结果是污染的，所以变量 sql1 也是污染的。 调用 Request。QueryString(“foo”) 的返回结果 sql2 是污染的。 函数 MySqlStuff 被调用，它的参数 sql1，sql2 都是污染的。分了分析函数的处理过程，根据第 6 行函数的声明，标记其参数 cmd1，cmd2 是污染的。 第 10 行是程序的 Sink 点，函数 conn。Execute 执行 SQL 操作，其参数 cmd2 是污染的，进而发现污染数据从 Source 点传播到 Sink 点。因此，认为程序存在 SQL 注入漏洞 动态污点分析技术动态污点分析是在程序运行的基础上，对数据流或控制流进行监控，从而实现对数据在内存中的显式传播、数据误用等进行跟踪和检测。动态污点分析与静态污点分析的唯一区别在于静态污点分析技术在检测时并不真正运行程序，而是通过模拟程序的执行过程来传播污点标记，而动态污点分析技术需要运行程序，同时实时传播并检测污点标记。 动态污点分析技术可分为三个部分： 污点数据标记：程序攻击面是程序接受输入数据的接口集，一般由程序入口点和外部函数调用组成。在污点分析中，来自外部的输入数据会被标记为污点数据。根据输入数据来源的不同，可分为三类：网络输入、文件输入和输入设备输入。 污点动态跟踪：在污点数据标记的基础上，对进程进行指令粒度的动态跟踪分析，分析每一条指令的效果，直至覆盖整个程序的运行过程，跟踪数据流的传播。 动态污点跟踪通常基于以下三种机制 动态代码插桩：可以跟踪单个进程的污点数据流动，通过在被分析程序中插入分析代码，跟踪污点信息流在进程中的流动方向。 全系统模拟：利用全系统模拟技术，分析模拟系统中每条指令的污点信息扩散路径，可以跟踪污点数据在操作系统内的流动。 虚拟机监视器：通过在虚拟机监视器中增加分析污点信息流的功能，跟踪污点数据在整个客户机中各个虚拟机之间的流动。 污点动态跟踪通常需要影子内存（shadow memory）来映射实际内存的污染情况，从而记录内存区域和寄存器是否是被污染的。对每条语句进行分析的过程中，污点跟踪攻击根据影子内存判断是否存在污点信息的传播，从而对污点信息进行传播并将传播结果保存于影子内存中，进而追踪污点数据的流向。 一般情况下，数据移动类和算数类指令都将造成显示的信息流传播。为了跟踪污点数据的显示传播，需要在每个数据移动指令和算数指令执行前做监控，当指令的结果被其中一个操作数污染后，把结果数据对应的影子内存设置为一个指针，指向源污染点操作数指向的数据结构。 污点误用检查：在正确标记污点数据并对污点数据的传播进行实时跟踪后，就需要对攻击做出正确的检测即检测污点数据是否有非法使用的情况。 动态污点分析的优缺点： 优点：误报率较低，检测结果的可信度较高。 缺点： 漏报率较高：由于程序动态运行时的代码覆盖率决定的。 平台相关性较高：特定的动态污点分析工具只能够解决在特定平台上运行的程序。 资源消耗大：包括空间上和时间上。 动态污点分析的方法实现1.污点数据标记污点数据通常主要是指软件系统所接受的外部输入数据，在计算机中，这些数据可能以内存临时数据的形式存储，也可能以文件的形式存储。当程序需要使用这些数据时，一般通过函数或系统调用来进行数据访问和处理，因此只需要对这些关键函数进行监控，即可得到程序读取或输出了什么污点信息。另外对于网络输入，也需要对网络操作函数进行监控。 识别出污点数据后，需要对污点进行标记。污点生命周期是指在该生命周期的时间范围内，污点被定义为有效。污点生命周期开始于污点创建时刻，生成污点标记，结束于污点删除时刻，清除污点标记。 污点创建 将来自于非可靠来源的数据分配给某寄存器或内存操作数时 将已经标记为污点的数据通过运算分配给某寄存器或内存操作数时 污点删除 将非污点数据指派给存放污点的寄存器或内存操作数时 将污点数据指派给存放污点的寄存器或内存地址时，此时会删除原污点，并创建新污点 一些会清除污点痕迹的算数运算或逻辑运算操作时 2.污点动态跟踪当污点数据从一个位置传递到另一个位置时，则认为产生了污点传播。污点传播规则： 指令类型 传播规则 举例说明 拷贝或移动指令 T(a)&lt;-T(b) mov a， b 算数运算指令 T(a)&lt;-T(b) add a， b 堆栈操作指令 T(esp)&lt;-T(a) push a 拷贝或移动类函数调用指令 T(dst)&lt;-T(src) call memcpy 清零指令 T(a)&lt;-false xor a， a 注：T(x) 的取值分为 true 和 false 两种，取值为 true 时表示 x 为污点，否则 x 不是污点。 对于污点信息流，通过污点跟踪和函数监控，已经能够进行污点信息流流动方向的分析。但由于缺少对象级的信息，仅靠指令级的信息流动并不能完全给出要分析的软件的确切行为。因此，需要在函数监控的基础上进行视图重建，如获取文件对象和套接字对象的详细信息，以方便进一步的分析工作。 根据漏洞分析的实际需求，污点分析应包括两方面的信息： 污点的传播关系，对于任一污点能够获知其传播情况。 对污点数据进行处理的所有指令信息，包括指令地址、操作码、操作数以及在污点处理过程中这些指令执行的先后顺序等。 污点动态跟踪的实现通常使用： 影子内存：真实内存中污点数据的镜像，用于存放程序执行的当前时刻所有的有效污点。 污点传播树：用于表示污点的传播关系。 污点处理指令链：用于按时间顺序存储与污点数据处理相关的所有指令。 当遇到会引起污点传播的指令时，首先对指令中的每个操作数都通过污点快速映射查找影子内存中是否存在与之对应的影子污点从而确定其是否为污点数据，然后根据污点传播规则得到该指令引起的污点传播结果，并将传播产生的新污点添加到影子内存和污点传播树中，同时将失效污点对应的影子污点删除。同时由于一条指令是否涉及污点数据的处理，需要在污点分析过程中动态确定，因此需要在污点处理指令链中记录污点数据的指令信息。 3.污点误用检查污点敏感点，即 Sink 点，是污点数据有可能被误用的指令或系统调用点，主要分为： 跳转地址：检查污点数据是否用于跳转对象，如返回地址、函数指针、函数指针偏移等。具体操作是在每个跳转类指令（如call、ret、jmp等）执行前进行监控分析，保证跳转对象不是污点数据所在的内存地址。 格式化字符串：检查污点数据是否用作printf系列函数的格式化字符串参数。 系统调用参数：检查特殊系统调用的特殊参数是否为污点数据。 标志位：跟踪标志位是否被感染，及被感染的标志位是否用于改变程序控制流。 地址：检查数据移动类指令的地址是否被感染。 在进行污点误用检查时，通常需要根据一些漏洞模式来进行检查，首先需要明确常见漏洞在二进制代码上的表现形式，然后将其提炼成漏洞模式，以更有效地指导自动化的安全分析。 动态污点分析的实例分析下面我们来看一个使用动态污点分析的方法检测缓冲区溢出漏洞的例子。 12345678910111213141516void fun(char *str)&#123; char temp[15]； printf(&quot;in strncpy， source： %s\\n&quot;， str)； strncpy(temp， str， strlen(str))； // Sink 点&#125;int main(int argc， char *argv[])&#123; char source[30]； gets(source)； // Source 点 if (strlen(source) &lt; 30) fun(source)； else printf(&quot;too long string， %s\\n&quot;， source)； return 0；&#125; 漏洞很明显， 调用 strncpy 函数存在缓冲区溢出。 程序接受外部输入字符串的二进制代码如下： 12345670x08048609 &lt;+51&gt;： lea eax，[ebp-0x2a]0x0804860c &lt;+54&gt;： push eax0x0804860d &lt;+55&gt;： call 0x8048400 &lt;gets@plt&gt;...0x0804862c &lt;+86&gt;： lea eax，[ebp-0x2a]0x0804862f &lt;+89&gt;： push eax0x08048630 &lt;+90&gt;： call 0x8048566 &lt;fun&gt; 程序调用 strncpy 函数的二进制代码如下： 1234567890x080485a1 &lt;+59&gt;： push DWORD PTR [ebp-0x2c]0x080485a4 &lt;+62&gt;： call 0x8048420 &lt;strlen@plt&gt;0x080485a9 &lt;+67&gt;： add esp，0x100x080485ac &lt;+70&gt;： sub esp，0x40x080485af &lt;+73&gt;： push eax0x080485b0 &lt;+74&gt;： push DWORD PTR [ebp-0x2c]0x080485b3 &lt;+77&gt;： lea eax，[ebp-0x1b]0x080485b6 &lt;+80&gt;： push eax0x080485b7 &lt;+81&gt;： call 0x8048440 &lt;strncpy@plt&gt; 首先，在扫描该程序的二进制代码时，能够扫描到 call &lt;gets@plt&gt;，该函数会读入外部输入，即程序的攻击面。确定了攻击面后，我们将分析污染源数据并进行标记，即将 [ebp-0x2a] 数组（即源程序中的source）标记为污点数据。程序继续执行，该污染标记会随着该值的传播而一直传递。在进入 fun() 函数时，该污染标记通过形参实参的映射传递到参数 str 上。然后运行到 Sink 点函数 strncpy()。该函数的第二个参数即 str 和 第三个参数 strlen(str) 都是污点数据。最后在执行 strncpy() 函数时，若设定了相应的漏洞规则（目标数组小于源数组），则漏洞规则将被触发，检测出缓冲区溢出漏洞。 污点分析在实际应用中的关键技术污点分析被广泛地应用在系统隐私数据泄露、安全漏洞等问题的检测中.在实际应用过程中,由于系统框架、语言特性等方面的差异,通用的污点分析技术往往难以适用.比如:系统框架的高度模块化以及各模块之间复杂的调用关系导致污点源到汇聚点的传播路径变得复杂、庞大,采用通用的污点分析技术可能面临开销难以接受的问题;通用的污点分析技术对新的语言特性支持有限等.为此,需要针对不同的应用场景,对通用的污点分析技术进行扩展或定制 本节以两个代表性的应用场景——智能手机的隐私泄漏检测和Web应用安全漏洞检测为切入点,总结近10年来污点分析技术在上述领域的应用实践过程中所面临的问题和关键解决技术 检测智能手机隐私泄露针对Android的污点传播分析也围绕组件展开,按照传播可能通过的模块的不同,分为组件内污点传播、组件间污点传播、组件与库函数之间的污点传播这3类(如图7所示).接下来将分别介绍针对这3类传播问题的静态和动态污点传播分析技术 静态污点分析1.组件内污点传播分析组件内部污点分析面临的主要问题是如何构建完整的分析模型.不同于传统的C/C++程序(有唯一的Main函数入口),Android应用程序存在有多个入口函数的情况.这个情况源于Android应用程序复杂的运行生命周期(例如onCreate,onStart,onResume,onPause等)以及程序中大量存在的回调函数和异步函数调用.由于任何的程序入口都有可能是隐私数据的来源,在静态的污点分析开始之前必须构建完整的应用程序模型,以确保程序中每一种可能的执行路径都会被静态污点传播分析覆盖到 LeakMiner[^4]和CHEX[^5]尝试使用增量的方法构建系统调用图. Arzt等人设计的FlowDroid[^6]提出了一种更系统的构建Android程序完整分析模型的方法:首先,通过XML配置文件提取与Android生命周期相关的入口函数,将这些方法作为节点,并根据Android生命周期构建调用图(如图8所示);其次,对于生命周期内的回调函数,在该调用图的基础上增加不透明谓词节点(即图8中菱形的P节点);然后,增量式地将回调函数加入这个函数调用图;最后,将调用图上所有的执行入口连接到一个虚假的Main函数上.FlowDroid中的一次合法的执行,就是对调用图进行的一次遍历 Gordon等人[^7]提出的DroidSafe使用Android设备实现(Android device implementation)来构建Android的完整分析模型.Android设备实现是对Android运行环境的一个简单模拟,它使用Java语言,结合Android Open Source Porject(AOSP),实现了与原Android接口语义等价的模型,并使用精确分析存根(accurate analysis stub)将AOSP代码之外的函数加入到模型中 2.组件间污点传播分析即使正确分析了组件内的数据流关系,污点数据仍然可能通过组件间的数据流来传递,从而造成信息泄露.如上图7左侧所示,即使保证了对组件A内部污点传播的精确分析,组件A仍然可能通过调用方法startActivityforResult()将信息传递给组件B,再通过组件B产生泄露.因此,针对Android应用的污点分析还需要分析出组件间所有可能的数据流信息.组件间通信是通过组件发送Intent消息对象完成的.Intent按照参数字段是否包含目标组件名称分为显式Intent和隐式Intent.如图9所示:显式Intent对象使用一个包含目标组件名称的参数显式地指定通信的下一个组件;隐式Intent使用action,category等域隐式地让Android系统通过Intent Filter自动选择一个组件调用.目前,解决该问题的主要思想是利用Intent参数信息分析组件间的数据流 解决组件间数据流的前提是解析Intent的目的地,解析Intent目的地包括解析显式Intent的目的地和隐式Intent的目的地.由于显式Intent的目的地可以直接通过初始化Intent的地址字符串参数获得,目前,解析显式Intent目的地的常用方法是使用字符串分析工具提取Intent中字符串参数的信息. 解析隐式Intent目的地的主要方法是分析配置文件信息与Intent Filter注册器之间的映射关系,建立发送Intent组件和接受Intent组件之间的配对关系.在解析出Intent目的地之后,问题的重点转移到如何提高组件间数据流分析的精度上. Klieber等人尝试在已经建立好的组件内污点分析的基础上,结合推导规则来分析组件间数据流.在分析之前,需要收集组件内部的污点源和汇聚点以及组件内Intent的发送目的地标签等信息.表4和表5给出了推导规则的前提定义和具体的推导规则,其中,一次完整的分析是指根据已知组件内部的信息src→sinksrc→sin**k以及推导规则识别所有src′→sink′src′→sin**k′的流集合 Octeau等人尝试使用现有的程序分析方法提高组件间数据流分析的精度,他们将组件间数据流分析问题转化成IDE(interprocedural distributive environment)问题[58]进行求解.DroidSafe设计了一种对象敏感的别名分析技术,在此基础上提供的精度优化方法包括:提取Intent的目的地的字符串参数、将Intent目的地的初始化函数嵌入到目的组件当中以提高别名分析的精度,同时,增加处理Android Service的支持 组件与库函数之间的污点传播分析组件与库函数之间的污点传播分析面临的主要问题包括对Android库函数自身庞大的代码量的分析以及组件和某些库函数使用的实现语言不同(Android组件通常用Java实现,而本地库则采用C/C++代码编写)这两方面 动态污点分析Android系统中的动态污点同样需要分析组件内污点传播、组件间污点传播以及组件代码与本地库之间的污点传播.动态污点分析面临的主要挑战是系统信息除了在系统内部通过DEX指令传播以外,还会经过其他的通道,如本地库、网络、文件等. 1.组件内的污点传播2.组件间的污点传播3.组件与本地库函数间的污点传播包括污点数据通过本地库代码或文件进行传播.TaintDroid通过设计后置条件对本地代码的函数进行污点传播.后置条件为: (a) 所有本地代码访问的外部变量都会被标记上污点标签; (b) 根据预定义规则将被赋值的函数返回值也标记上污点标签 总结污点分析作为信息流分析的一种实践技术,被广泛应用于互联网及移动终端平台上应用程序的信息安全保障中.本文介绍了污点分析的基本原理和通用技术,并针对近年来污点分析在解决实际应用程序安全问题时遇到的问题和关键解决技术进行了分析综述.不同于基于安全类型系统的信息流分析技术,污点分析可以不改变程序现有的编程模型或语言特性,并提供精确信息流传播跟踪.在实际应用过程中,污点分析还需要借助传统的程序分析技术的支持,例如静态分析中的数据流分析、动态分析中的代码重写等技术.另外,结合测试用例生成技术、符号执行技术以及虚拟机技术,也会给污点分析带来更多行之有效的解决方案 参考文献[^1]:Vogt P, Nentwich F, Jovanovic N, Kirda E, Kruegel C, Vigna G. Cross site scripting prevention with dynamic data tainting and static analysis. In: Proc. of the NDSS 2007. 2007. 12. http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.72.4505[^2]:Gordon MI, Kim D, Perkins JH, Gilham L, Nguyen N, Rinard MC. Information flow analysis of Android applications in DroidSafe. In: Proc. of the NDSS 2015. 2015. [doi: 10.14722/ndss.2015.23089][^3]:Rasthofer S, Arzt S, Bodden E. A machine-learning approach for classifying and categorizing android sources and sinks. In: Proc. of the Network and Distributed System Security Symp. (NDSS). 2014. [doi: 10.14722/ndss.2014.23039] [^4]:Yang Z, Yang M. Leakminer: Detect information leakage on Android with static taint analysis. In: Proc. of the Software Engineering. IEEE, 2012. 101−104. [doi: 10.1109/WCSE.2012.26][^5]:Lu L, Li Z, Wu Z, Lee W, Jiang G. Chex: Statically vetting Android apps for component hijacking vulnerabilities. In: Proc. of the 2012 ACM Conf. on Computer and Communications Security. ACM Press, 2012. 229−240. [doi: 10.1145/2382196.2382223][^6]:Arzt S, Rasthofer S, Fritz C, Bodden E, Bartel A, Klein J, Le Traon Y, Octeau D, McDaniel P. Flowdroid: Precise context, flow, field, object-sensitive and lifecycle-aware taint analysis for Android apps. ACM SIGPLAN Notices, 2014,49(6):259−269. [doi: 10.1145/2594291.2594299][^7]:Gordon MI, Kim D, Perkins JH, Gilham L, Nguyen N, Rinard MC. Information flow analysis of Android applications in DroidSafe. In: Proc. of the NDSS 2015. 2015. [doi: 10.14722/ndss.2015.23089] 原文链接","categories":[{"name":"程序分析","slug":"程序分析","permalink":"https://lwy0518.github.io/categories/%E7%A8%8B%E5%BA%8F%E5%88%86%E6%9E%90/"}],"tags":[{"name":"数据流","slug":"数据流","permalink":"https://lwy0518.github.io/tags/%E6%95%B0%E6%8D%AE%E6%B5%81/"},{"name":"污点分析","slug":"污点分析","permalink":"https://lwy0518.github.io/tags/%E6%B1%A1%E7%82%B9%E5%88%86%E6%9E%90/"},{"name":"依赖关系","slug":"依赖关系","permalink":"https://lwy0518.github.io/tags/%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB/"},{"name":"Source/Sink","slug":"Source-Sink","permalink":"https://lwy0518.github.io/tags/Source-Sink/"}],"author":"lwy"},{"title":"EOSIOAnalyzer架构","slug":"EOSIOAnalyzer架构","date":"2021-12-13T11:00:39.000Z","updated":"2021-12-27T02:33:24.263Z","comments":true,"path":"2021/12/13/EOSIOAnalyzer架构/","link":"","permalink":"https://lwy0518.github.io/2021/12/13/EOSIOAnalyzer%E6%9E%B6%E6%9E%84/","excerpt":"EOSIOAnalyzer目录 EOSIOAnalyzer 框架 Control flow graph builder Static analyzer 将得到的Wasm CFG转为IR CFG 对IR CFG基本块进行数据流分析 输出所有的EDB文件 程序介绍 分析脚本 Datalog规范 Vulnerability detector Fake EOS Transfer Forged Transfer Notification Block Information Dependency","text":"EOSIOAnalyzer目录 EOSIOAnalyzer 框架 Control flow graph builder Static analyzer 将得到的Wasm CFG转为IR CFG 对IR CFG基本块进行数据流分析 输出所有的EDB文件 程序介绍 分析脚本 Datalog规范 Vulnerability detector Fake EOS Transfer Forged Transfer Notification Block Information Dependency EOSIOAnalyzer EOSIOAnalyzer是一个用于分析EOSIO智能合约字节码的分析框架。分析框架由三个部分组成： Control flow graph builder Static analyzer Vulnerability detector 以上是该框架的主要部分。除了Vulnerability detector部分是通过 Datalog编写的（执行引擎为Souffle)，其他部分均用python编写。 Datalog大约900行，python大约3000行 下图是其框架图： Control flow graph builder​ 输入为Wasm字节码，如果是源代码，可以用现有的编译器（llvm，eosio.cdt，emscripten，rustup等等）编译为字节码，然后基于现有开源工具Octopus将Wasm字节码构造对应的控制流图，作为下一步的输入 Static analyzer 这是EOSIOAnalyzer的核心。由于EOS VM的基于堆栈的紧凑执行模型混淆了跳转地址，所以将 Wasm字节码转换为中间表示，其中执行堆栈被寄存器变量替换，然后构建合约的过程间控制流图（ICFG）以进行漏洞分析 将得到的Wasm CFG转为IR CFG​ 将上一步得到的Wasm CFG进行转换，将低级的wasm指令转为更高级中间表示（IR） 对IR CFG基本块进行数据流分析​ 对得到的IR CFG进行数据流分析，得到完整的数据传播关系（Def_Use） 细粒度分析得到过程内CFG（intra-procedural control flow graph）以及粗粒度分析得到调用图（call graph），结合得到过程间控制流图（ICFG，inter-procedural control flow graph） ​ 具体过程如下： 将 Wasm字节码转为Wasm基本块（在Control flow graph builder中已经实现） 将每个Wasm基本块转为对应的IR基本块 构造对应的IR CFG，作为程序src/exporter.py的输入，输出以下内容 状态转换函数： 输出所有的EDB（.facts）文件 edge：包含块内与块间之间的边 def：新赋值的变量，每个变量都是一个寄存器变量（唯一） use：每个语句需要使用之前定义的变量 op：wasm操作码 value：程序中的常量 imm：操作码需要的立即数 block_in_function：每个函数包含的块名 func_call_edge：包含所有直接调用（call）以及间接调用（call_indirect）之间的边 in_function：每个函数包含的语句（statement） is_function：程序中的所有函数（包括import、export、local） function_types：只包含export和local函数的签名（参数及返回值） static_datas：程序中的常量及字符串 block_dom：包含块内与块间的dominator关系 types：间接调用对应的函数类型（call_indirect的第一个立即数） 程序介绍 实现：目录src下包含大部分python程序，下面将介绍这些程序功能 src/cfg.py：定义基类ControlFlowGraph和BasicBlock src/wasm_cfg.py：专门的cfg.ControlFlowGraph和cfg.BasicBlock用于表示Wasm字节码的控制流图 src/ir_cfg.py：专门wasm_cfg.*用于在我们的中间表示中表示合约的类。实现定义ir_cfg.Destackifier了一个将单个wasm_cfg.EVMBasicBlock实例转换为ir_cfg.IRBasicBlock实例的类；和辅助类IROp, IRAssignOp, IRArg,IRCallOp 以及IRLocRef我们的中间表示 src/exporter.py：定义了从给定的控制流图生成 EOSIOAnalyzer输出表示的类。在其构造函数中接受一个 CFG 实例，并包含一个产生输出的export()函数，输出所有EDB文件 src/dataflow.py： src/lattice.py：实现lattice类，用于定点数据流分析 src/memtypes.py：用于表示和使用我们的 IR 中使用的寄存器变量的类。变量可以是常数、设定值或未知 src/wasm_inst.py：使用官方文档中的信息定义 Wasm指令集 src/number.py：包含所有与number相关的函数和类 src/requirement.txt：包含程序运行所需要的包 分析脚本 我们的分析脚本tools/bulk_analysis.py可以分析单个合约字节码目录，也可以分析包含多个智能合约字节码目录（可以多线程运行），只需修改路径即可。结合Souffle 引擎以及编写的漏洞规则，最终会输出一个json格式的文件，包含最终的漏洞分析结果 Datalog规范 我们编写的Datalog规则在目录tools/spec.dl、tools/instructions.dl中 例如，以下规则用于检测Fake EOS Transfer漏洞 1234567.decl DetectFakedEosTransfer(call_stmt: Statement).output DetectFakedEosTransferDetectFakedEosTransfer(call_stmt) :- NotEosioToken(true_stmt), Call_Transfer(call_stmt), Dominates(call_stmt, true_stmt). Vulnerability detector Fake EOS Transfer 描述：由于eosio.token源代码完全公开的，所以任何人都能复制其源代码，并发布一个token（相同的名字、符号和代码），虚假的EOS和官方的唯一不同就是具有不同的发布人。或者直接调用漏洞合约的transfer函数进行转账 规则：code == N(eosio.token) –&gt; action == N(transfer) 在apply函数中，看是否存在这样一条验证路径，如存在则不存在该漏洞，反之则存在； Forged Transfer Notification 描述：攻击者在 EOS 网络中控制两个账户 A 和 B，通过账户 A 向账户 B 发送真正的 EOS，eosio.token 合约在转账成功后会向 B 发送 notification。当账户 B 收到 notification后随即转发到受害者智能合约 C Transfer –&gt; _self == to 在找到的所以可能“transfer”函数中，看是否存在*_self*与to的比较，如存在则不存在该漏洞，反之则存在； Block Information Dependency 描述：开发者一般调用tapos_block_prefix或tapos_block_number获得区块链信息，并将其返回值作为控制流的判断条件，并最后触发调用send_inline函数进行转账行为 tapos_block_prefix/tapos_block_num –&gt; send_inline 如果存在一条由tapos_block_prefix/tapos_block_num函数作为控制条件并最后触发send_inline函数的调用，则存在该漏洞，反之不存在","categories":[{"name":"EOSIO","slug":"EOSIO","permalink":"https://lwy0518.github.io/categories/EOSIO/"}],"tags":[{"name":"数据流","slug":"数据流","permalink":"https://lwy0518.github.io/tags/%E6%95%B0%E6%8D%AE%E6%B5%81/"},{"name":"EOSIO","slug":"EOSIO","permalink":"https://lwy0518.github.io/tags/EOSIO/"},{"name":"编译器","slug":"编译器","permalink":"https://lwy0518.github.io/tags/%E7%BC%96%E8%AF%91%E5%99%A8/"},{"name":"漏洞检测","slug":"漏洞检测","permalink":"https://lwy0518.github.io/tags/%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8B/"},{"name":"静态分析","slug":"静态分析","permalink":"https://lwy0518.github.io/tags/%E9%9D%99%E6%80%81%E5%88%86%E6%9E%90/"},{"name":"Datalog","slug":"Datalog","permalink":"https://lwy0518.github.io/tags/Datalog/"},{"name":"CFG","slug":"CFG","permalink":"https://lwy0518.github.io/tags/CFG/"},{"name":"IR","slug":"IR","permalink":"https://lwy0518.github.io/tags/IR/"}],"author":"lwy"},{"title":"程序分析之中间表示（Intermediate Representation）","slug":"程序分析之中间表示（Intermediate-Representation）","date":"2021-12-10T07:43:30.000Z","updated":"2021-12-26T07:47:51.812Z","comments":true,"path":"2021/12/10/程序分析之中间表示（Intermediate-Representation）/","link":"","permalink":"https://lwy0518.github.io/2021/12/10/%E7%A8%8B%E5%BA%8F%E5%88%86%E6%9E%90%E4%B9%8B%E4%B8%AD%E9%97%B4%E8%A1%A8%E7%A4%BA%EF%BC%88Intermediate-Representation%EF%BC%89/","excerpt":"静态分析程序静态分析（Program Static Analysis）是指在不运行代码的方式下，通过词法分析、语法分析、控制流、数据流分析等技术对程序代码进行扫描，验证代码是否满足规范性、安全性、可靠性、可维护性等指标的一种代码分析技术。静态分析技术向模拟执行的技术发展以能够发现更多传统意义上动态测试才能发现的缺陷，从而提高开发效率和软件质量。本文介绍部分在静态代码分析中使用的中间表示的概念，主要包括抽象语法树、三地址码、SSA形式，及CFG和RTL等概念","text":"静态分析程序静态分析（Program Static Analysis）是指在不运行代码的方式下，通过词法分析、语法分析、控制流、数据流分析等技术对程序代码进行扫描，验证代码是否满足规范性、安全性、可靠性、可维护性等指标的一种代码分析技术。静态分析技术向模拟执行的技术发展以能够发现更多传统意义上动态测试才能发现的缺陷，从而提高开发效率和软件质量。本文介绍部分在静态代码分析中使用的中间表示的概念，主要包括抽象语法树、三地址码、SSA形式，及CFG和RTL等概念 中间表示（Intermediate Representation）抽象语法树（Abstract Syntax Tree，AST）在介绍AST时，我们用一个简单的例子：x = 3 + 4 * y 这个表达式作为例子来进行介绍： AST： 是源代码的抽象语法结构的树状表示，树上的每个节点都表示源代码中的一种结构，之所以说是抽象的，是因为抽象语法树并不会表示出真实语法出现的每一个细节 抽象语法树，其实就是用树状结构表示语法结构，也没有说必须是什么形式，只要能忠实地反映出源码的格式即可 当然，一般资料中在进行介绍时，都是以操作符作为根节点，画个树状的结构来表示，这里咱们也简单画一个意思一下，如下图： 三地址码（Three Address Code，TAC/3AC）三地址码是一种有意思的中间表示，当前也是编译原理中用得最火的。这里我给大家梳理一种我的理解上的概念，那就是，刨掉赋值操作，最多只有一个操作符，先看下面的几个例子 x = y bop z x = uop y x = y goto L 如上，第一个，除了赋值之外，只有 bop 一个操作符，第二个，只有 uop 一个操作符，第三个没有操作符，同时，操作符的概念可以进一步扩展到函数调用等，例如 call fun(a, b, c, d)，虽然有四个操作数，但是我们认为 call fun只是一个操作符。 如上面 x = 3 + 4 * y 转换为三地址码如下： 123456t1 = 4t2 = yt3 = t1 * t2t4 = 3t5 = t4 + t3x = t5 当然，有些形式下会减少临时变量的使用，尽量复用原来的变量或者常量，形成的三地址码如下： 12t1 = 4 * yx = 3 + t1 三地址码最初只是处理类似于 x = y bop z 这种形式的语句，而提出来的“三个操作数”的意思，随着语法的扩充，也并不是完全就是“三地址”。 AST和三地址码对比以下介绍几点AST和三地址码的对比特点： 源码相关性 AST中的节点与输入源代码中的各个语法元素一一对应，忠实地体现了源码的内容和语法特性，因此AST与源码强相关；三地址码就是从AST进一步抽象的一种中间表示，更接近机器语言，可以认为和语言无关，是连接前后端的一种中间表示 变化频繁程度 因为AST需要忠实地体现出源代码的语法元素，因此在对应的编程语言升级时，对应的AST必然会跟着发生变化，比如Java，从Java7变成Java8，增加了大量的Lambda表达式、函数引用等特性，所以AST节点也需要增加这些语法节点，所以AST的版本需要随着语言发布而不断变化。 但是三地址码是一种经过处理的语言无关的中间表示，即使源代码结构变化，AST结构变化，但是转换后的三地址码是稳定的，不会经常发生变化，构造在三地址码上面的分析算法就相对比较稳定 结构 AST体现源码的结构，需要匹配源码的语法，因此一般结构比较复杂，而三地址经过处理，一般比较紧凑，简单。例如，Java中，对 for，while，do while 有多种不同的循环方式，但是，其实内容大同小异，但是在AST层面，就是不一样的，但是转换为三地址码后，所表达的控制语义是完全一样的 表达信息 AST表达了源码的信息，因此可以在AST上做程序结构的检查，但是三地址码中，可以更好地包含了程序控制流和数据流信息，能进行更深层次的流敏感分析，过程间分析，上下文敏感分析和对象敏感分析等等，从而实现各种更高难度的程序漏洞检查。 同时，三地址码因为是语言无关的， 所以在部分静态代码分析工具实现时，会对不同的三地址码，实现一个分析引擎，只是通过开发不同语言的规则，实现对不同语言的能力的覆盖，而AST是无法做到这一点的。因此，三地址码也被认为是静态代码分析的基础 **静态单赋值形式**（Static Single Assignment Form，SSA）文件地址 SSA概念及分类 SSA概念 在编译器的设计中，静态单赋值形式通常简写为SSA form或是SSA，是中介码的特性，每个变数仅被赋值一次。在原始的IR中，已存在的变数可被分割成许多不同的版本，在许多教科书当中通常会将旧的变数名称加上一个下标而成为新的变数名称，以至于标明每个变数及其不同版本。在SSA中，UD链（use-define chain，赋值代表define，使用变数代表use）是非常明确，而且每个仅包含单一元素 以下面的代码为例： 12345678910public void test(int x) &#123; int y = 0; if (x &gt; 3) &#123; y = x + 4; &#125; else &#123; y = 10; &#125; int z = y + 3; System.out.println(z);&#125; 以下图为例，左图是原始代码，里面有分支， y 变量在不同路径中有不同赋值，最后打印 z的值。右图是等价的 SSA 形式，y 变量在两个分支中被改写为 y2, y3，在控制流交汇处插入φ函数，合并了来自不同边的 y2, y3值, 赋给 y4 最后z由y4生成 其实要讲SSA形式，就不能离开对DU Chain（Define-Use Chain）和UD Chain（Use-Define Chain）的介绍，因为很多地方对SSA的概念的介绍，都是从DU Chain和UD Chain引起的。Use-Define Chain 是一个数据结构，包含一个Define变量，以及它的全部Use的集合。相对的，Define-Use Chain 包含一个Use变量，以及它的全部 Define的集合。 另外一种SSA的描述，就是在 Define-Use Chain中，每一个Use变量，只会有一个Define，例如，在前面例子中，z = y + 3 中，因为此时 y可能在两个分支中赋值，因此，对于变量 z = y + 3 中，y 的Use来说，有两个 Define，但是，通过更改为 SSA形式，z = y + 3 中，y只有一个 Define，那就是 y4。因此，通过将三地址码转为SSA形式，可以很大程度上，简化Use-Define Chain和Define-Use Chain。 SSA分类 SSA 有几种不同分类（主要是最小SSA、剪枝SSA、半剪枝SSA，另外两种严格SSA和最大SSA，大部分资料上都没有看到，只是在少部分资料中有见到，所以简单提一下） 最小SSA 最小SSA有以下特点：同一原始名字的两个不同定义的路径汇合处都插入一个φ函数。这样得到符合两大特征的且拥有最少φ函数数量的 SSA 形式。但是这里的最小不包含优化效果，比如死代码消除。如上面图2.1节，就是一个最小SSA形式 剪枝SSA 如果变量在基本块的入口处不是活跃 (live) 的，就不必插入φ函数。一种方法是在插入 φ函数的时候计算活跃变量分析。另一种剪枝方式是在最小SSA上做死代码消除，删掉多余的φ函数。如下面的例子，y在分支执行完后，在最后的BB块中不再使用，y已经不再活跃，此时没必要在这个节点添加φ函数，如下面右图红色标出来的位置（说明：虽然不是剪枝SSA，但是仍然是最小SSA） 半剪枝SSA 鉴于剪枝 SSA 的成本，可以稍微折衷一点。插入φ函数前先去掉非跨越基本块的变量名。这样既减少了名字空间也没有计算活跃变量集的开销。如下图所示，y变量除了Define，并没有Use，所以，变量y其实可以去掉，如下右图 严格SSA 如果一个 SSA中，每个Use被其Define支配（如果从程序入口到一个结点 A 的所有路径，都先经过结点B，则称A被B支配），那么称为严格 SSA（实际上，在强类型语言中，这种情况比较少，因为没有定义，就不允许使用，在少数动态类型语言中，允许没有定义就可以使用的才有这类问题） 最大SSA 最大SSA是相对最小SSA而言的，就是在每个汇合点处为每个变量放置一个φ函数。很显然，这种方法会导致SSA的使用效率最差，用户体验也很差，我估计谁生成的SSA是这样的形式，会被使用的人打死的 SSA形式和普通三地址码对比其实对比SSA形式和普通的三地址码形式，只有一个区别，那就是，SSA形式，对于每个Use，只会有一个Define。两者在一定程度上，还是非常类似的。那么主要对比在于两种形式的各自的优缺点： SSA形式相对于三地址码，会引入大量的额外的临时变量，同时需要插入φ函数，还需要维护这些临时变量到原始变量的映射关系（当然，仁者见仁，智者见智，也有资料觉得这些额外的临时变量可以忽略，驳斥这个观点为谬论，不过的确还是有其不舒服的地方的） SSA形式的优势在于，SSA形式简化了DU Chain和UD chain，构建了一种稀疏结构，可以简化数据流分析（一般基于三地址码，需要基于传统的数据流分析来进行分析，称为dense分析，基于SSA形式，可以构造值依赖关系，基于值流分析，也称为sparse分析，同时，SSA形式也隐含了一定的程序流信息） SSA形式相比于普通三地址码，可以优化常量传播、值依赖分析、死代码、重复代码删除等 控制流图（Control Flow Graph，CFG） 也叫控制流程图，是一个过程或程序的抽象表现，是用在编译器中的一个抽象数据结构，由编译器在内部维护，代表了一个程序执行过程中会遍历到的所有路径。它用图的形式表示一个过程内所有基本块执行的可能流向, 也能反映一个过程的实时执行过程 基本块（Basic Block） 特点： 单入口、单出口、每个块内的语句都是按顺序执行的，不能有分支和跳转 只能从第一条语句进入该基本块，不能够以某种方式跳入该基本块的中间 基本块内的语句在执行时必须从最后一条语句离开，不能够执行到一半跳转到其它的基本块 CFG CFG是一个由基本块组成的有向图，每个节点都是一个基本块。如果程序的执行路径可能从一个基本块$B_1$进入另一个基本块**$B_2$，$B_1$有一条指向$ B_2 $**的边 其中： $N:$表示所有基本块节点的集合 $E:$表示所有边的集合 $n_0:$表示首节点 CFG具有如下的两条性质： CFG 必然有唯一的一个入口点 首节点必然支配CFG中其他的所有节点（即从首节点到CFG上其他任何一个节点都有一条路可以连通） 寄存器传输语言（Register Transfer Language，RFL） 又译为暂存器转换语言、寄存器转换语言，一种中间语言，使用于编译器中。与汇编语言很接近。寄存器传递语言被用于描述一个架构中寄存器传输级上的数据流。 在学术论文和教科书中，寄存器传递语言被认为是一种与架构无关的汇编语言。GCC的中间语言，也被称为寄存器传递语言，风格类似于LISP。GCC的前端（front-end）会先将编程语言转译成RTL，之后再利用后端（back-end）转化成机器代码 以下一些文章用到相关技术： Vandal Securify2 MadMax Gigahorse Ethainter 原文链接","categories":[{"name":"程序分析","slug":"程序分析","permalink":"https://lwy0518.github.io/categories/%E7%A8%8B%E5%BA%8F%E5%88%86%E6%9E%90/"}],"tags":[{"name":"中间表示（IR）","slug":"中间表示（IR）","permalink":"https://lwy0518.github.io/tags/%E4%B8%AD%E9%97%B4%E8%A1%A8%E7%A4%BA%EF%BC%88IR%EF%BC%89/"},{"name":"CFG","slug":"CFG","permalink":"https://lwy0518.github.io/tags/CFG/"},{"name":"AST","slug":"AST","permalink":"https://lwy0518.github.io/tags/AST/"},{"name":"TAC","slug":"TAC","permalink":"https://lwy0518.github.io/tags/TAC/"},{"name":"SSA","slug":"SSA","permalink":"https://lwy0518.github.io/tags/SSA/"},{"name":"RTL","slug":"RTL","permalink":"https://lwy0518.github.io/tags/RTL/"}],"author":"lwy"},{"title":"hexo博客迁移到另外一台电脑","slug":"hexo博客迁移到另外一台电脑","date":"2021-12-10T07:10:46.000Z","updated":"2021-12-22T02:59:05.560Z","comments":true,"path":"2021/12/10/hexo博客迁移到另外一台电脑/","link":"","permalink":"https://lwy0518.github.io/2021/12/10/hexo%E5%8D%9A%E5%AE%A2%E8%BF%81%E7%A7%BB%E5%88%B0%E5%8F%A6%E5%A4%96%E4%B8%80%E5%8F%B0%E7%94%B5%E8%84%91/","excerpt":"复制原电脑上的数据 注：不需要全部复制 _config.yml：站点配置文件 package.json：应用程序数据，指明hexo的版本等信息，类似于一般软件中的关于按钮 scaffolds/：layout模板文件目录，其中的md文件可以添加编辑 source/： 文章源码目录，该目录下的markdown和html文件均会被hexo处理。该页面对应repo的根目录，404文件、favicon.ico文件，CNAME文件等都应该放这里，该目录下可新建页面目录。 drafts：草稿文章 posts：发布文章 themes/：主题文件","text":"复制原电脑上的数据 注：不需要全部复制 _config.yml：站点配置文件 package.json：应用程序数据，指明hexo的版本等信息，类似于一般软件中的关于按钮 scaffolds/：layout模板文件目录，其中的md文件可以添加编辑 source/： 文章源码目录，该目录下的markdown和html文件均会被hexo处理。该页面对应repo的根目录，404文件、favicon.ico文件，CNAME文件等都应该放这里，该目录下可新建页面目录。 drafts：草稿文章 posts：发布文章 themes/：主题文件 安装配置环境 安装node 安装git 再参考上一篇文章 下载相关插件123456# 将文章部署到github上的模块$ cnpm install hexo-deployer-git --save# 安装RSS插件$ cnpm install hexo-generator-feed --save# 添加Sitemap,加速网页收录速度$ cnpm install hexo-generator-sitemap --save","categories":[{"name":"博客","slug":"博客","permalink":"https://lwy0518.github.io/categories/%E5%8D%9A%E5%AE%A2/"}],"tags":[{"name":"博客","slug":"博客","permalink":"https://lwy0518.github.io/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"hexo","slug":"hexo","permalink":"https://lwy0518.github.io/tags/hexo/"}],"author":"lwy"},{"title":"EOSIO环境搭建及创建账户","slug":"EOSIO环境搭建及创建账户","date":"2021-12-10T02:01:59.000Z","updated":"2021-12-22T02:58:52.714Z","comments":true,"path":"2021/12/10/EOSIO环境搭建及创建账户/","link":"","permalink":"https://lwy0518.github.io/2021/12/10/EOSIO%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%E5%8F%8A%E5%88%9B%E5%BB%BA%E8%B4%A6%E6%88%B7/","excerpt":"环境搭建官方文档 钱包和账户","text":"环境搭建官方文档 钱包和账户 Nodeos（node + eos = nodeos）：运行节点的核心服务守护进程，用于区块生产、API 端点或本地开发 Cleos (cli + eos = cleos) ： 与区块链交互的命令行界面 (via nodeos) 和管理钱包 (via keosd) Keosd (key + eos = keosd) ： 管理钱包中的 EOSIO 密钥并为数字签名提供安全飞地的组件 可以参考下列解读图： 创建钱包1$ cleos wallet create -n wallet_name --to-console 其中：**-n是指定钱包名称（如果不指定则会默认生成一个default钱包）， wallet_name是你需要创建的钱包名（以下用lwy代替），–to-console**是将密钥输出到控制台（记得一定要保存这个密钥，因为要用于钱包的解锁） 查看创建的钱包1$ cleos wallet list 其中带**”*”**号指已解锁的钱包 钱包的解锁与加锁 解锁（会提示你输入钱包密钥） 1$ cleos wallet unlock -n lwy --password 加锁（不需要输入密钥） 1$ cleos wallet lock -n lwy 生成和导入公钥-私钥对生成公钥-私钥对 为了简单可以直接用一个公钥-私钥对（记得保存私钥，一定！一定 ！） 1$ cleos create key --to-console 导入公钥-私钥对 如果lwy钱包还没解锁，记得先解锁 将生成的公钥-私钥对导入lwy钱包内 1$ cleos wallet import -n lwy --private-key 5J9rzfgPNLuCL9j4AEc4RYcchvJQPaPNUtWuToRSeFAEayitM8v 创建和管理账户命令行及参数说明1$ cleos create account authorizing_account NEW_ACCOUNT OWNER_KEY ACTIVE_KEY 注：在这OWNER_KEY与ACTIVE_KEY是同一个，因为我为了简单只生成了一个公钥-私钥对 authorizing_account 是为帐户创建提供资金的帐户的名称 new_account 是您要创建的帐户的名称 owner_key是分配给帐户owner权限的公钥 active_key是分配给您帐户的active权限的公钥 新帐户名称必须符合以下准则： 必须在12个字符以内，包括12字符。 只能包含以下符号：.12345abcdefghijklmnopqrstuvwxyz 请注意，账户名称不允许使用6,7,8,9,0。 使用eosio初始账户创建新账户eosio帐户是用于引导EOSIO节点的特殊帐户。由于我们没有其他账户，所以用初始eosio账户来创建新帐户 eosio帐户的密钥可以在nodeos配置文件中找到，位于~/.local/share/eosio/nodeos/config/config.ini。 同时，记得解锁lwy钱包 首先，需要将默认账号eosio的私钥导入lwy钱包内： 1$ cleos wallet import -n lwy --private-key 5J9rzfgPNLuCL9j4AEc4RYcchvJQPaPNUtWuToRSeFAEayitM8v 然后，用初始eosio账户来创建新帐户testaccount： 1$ cleos create account eosio testaccount 5J9rzfgPNLuCL9j4AEc4RYcchvJQPaPNUtWuToRSeFAEayitM8v 查看账户信息1$ cleos get account testaccount -j -j 指信息以json格式输出 至此，EOSIO环境搭建以及账户创建已完成！！","categories":[{"name":"EOSIO","slug":"EOSIO","permalink":"https://lwy0518.github.io/categories/EOSIO/"}],"tags":[{"name":"EOSIO","slug":"EOSIO","permalink":"https://lwy0518.github.io/tags/EOSIO/"},{"name":"智能合约","slug":"智能合约","permalink":"https://lwy0518.github.io/tags/%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6/"}],"author":"lwy"},{"title":"EOSIO部署全过程","slug":"EOSIO部署全过程","date":"2021-12-10T01:19:12.000Z","updated":"2021-12-22T02:58:49.459Z","comments":true,"path":"2021/12/10/EOSIO部署全过程/","link":"","permalink":"https://lwy0518.github.io/2021/12/10/EOSIO%E9%83%A8%E7%BD%B2%E5%85%A8%E8%BF%87%E7%A8%8B/","excerpt":"","text":"","categories":[{"name":"EOSIO","slug":"EOSIO","permalink":"https://lwy0518.github.io/categories/EOSIO/"}],"tags":[{"name":"数据流","slug":"数据流","permalink":"https://lwy0518.github.io/tags/%E6%95%B0%E6%8D%AE%E6%B5%81/"},{"name":"EOSIO","slug":"EOSIO","permalink":"https://lwy0518.github.io/tags/EOSIO/"},{"name":"编译器","slug":"编译器","permalink":"https://lwy0518.github.io/tags/%E7%BC%96%E8%AF%91%E5%99%A8/"},{"name":"漏洞检测","slug":"漏洞检测","permalink":"https://lwy0518.github.io/tags/%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8B/"},{"name":"静态分析","slug":"静态分析","permalink":"https://lwy0518.github.io/tags/%E9%9D%99%E6%80%81%E5%88%86%E6%9E%90/"},{"name":"Datalog","slug":"Datalog","permalink":"https://lwy0518.github.io/tags/Datalog/"},{"name":"CFG","slug":"CFG","permalink":"https://lwy0518.github.io/tags/CFG/"},{"name":"IR","slug":"IR","permalink":"https://lwy0518.github.io/tags/IR/"}],"author":"lwy"},{"title":"数据流分析","slug":"数据流分析","date":"2021-12-07T07:31:36.000Z","updated":"2021-12-23T03:00:11.231Z","comments":true,"path":"2021/12/07/数据流分析/","link":"","permalink":"https://lwy0518.github.io/2021/12/07/%E6%95%B0%E6%8D%AE%E6%B5%81%E5%88%86%E6%9E%90/","excerpt":"基本原理数据流分析是一种用来获取相关数据沿着程序执行路径流动的信息分析技术。分析对象是程序执行路径上的数据流动或可能的取值 优点：具有更强的分析能力，适合需要考虑控制流信息且变量属性之操作十分简单的静态分析问题 缺点：分析效率低，过程间分析和优化算法复杂，编程工作量大，容易出错且效率低 一个数据流分析框架(D, L, F)包含: D：数据流的方向，前向或者后向 L：包含数值作用域V和操作符meet ⊓ 或 join ⊔ 的lattice F：一系列V to V的传递函数 Tips: 数据流分析可以看成在一个lattice的数值域上，迭代地使用传递函数和操作符","text":"基本原理数据流分析是一种用来获取相关数据沿着程序执行路径流动的信息分析技术。分析对象是程序执行路径上的数据流动或可能的取值 优点：具有更强的分析能力，适合需要考虑控制流信息且变量属性之操作十分简单的静态分析问题 缺点：分析效率低，过程间分析和优化算法复杂，编程工作量大，容易出错且效率低 一个数据流分析框架(D, L, F)包含: D：数据流的方向，前向或者后向 L：包含数值作用域V和操作符meet ⊓ 或 join ⊔ 的lattice F：一系列V to V的传递函数 Tips: 数据流分析可以看成在一个lattice的数值域上，迭代地使用传递函数和操作符 数据流分析的分类 对程序路径的分析精度分类 流不敏感分析（flow insensitive）：不考虑语句的先后顺序，按照程序语句的物理位置从上往下顺序分析每一语句，忽略程序中存在的分支 流敏感分析（flow sensitive）：考虑程序语句可能的执行顺序，通常需要利用程序的控制流图（CFG） 路径敏感分析（path sensitive）：不仅考虑语句的先后顺序，还对程序执行路径条件加以判断，以确定分析使用的语句序列是否对应着一条可实际运行的程序执行路径 分析程序路径的深度分类 过程内分析（intra-procedure analysis）：只针对程序中函数内的代码 过程间分析（inter-procedure analysis）：考虑函数之间的数据流，即需要跟踪分析目标数据在函数之间的传递过程 上下文不敏感分析（context-insensitive）：将每个调用或返回看做一个 “goto” 操作，忽略调用位置和函数参数取值等函数调用的相关信息 上下文敏感分析（context-sensitive）：对不同调用位置调用的同一函数加以区分 检测程序漏洞基于数据流的源代码漏洞分析的原理如下图所示： 代码建模 该过程通过一系列的程序分析技术获得程序代码模型。首先通过词法分析生成词素的序列，然后通过语法分析将词素组合成抽象语法树。如果需要三地址码，则利用中间代码生成过程解析抽象语法树生成三地址码。如果采用流敏感或路径敏感的方式，则可以通过分析抽象语法树得到程序的控制流图。构造控制流图的过程是过程内的控制流分析过程。控制流还包含分析各个过程之间的调用关系的部分。通过分析过程之间的调用关系，还可以构造程序的调用图。另外，该过程还需要一些辅助支持技术，例如变量的别名分析，Java 反射机制分析，C/C++ 的函数指针或虚函数调用分析等 代码解析：指词法分析、语法分析、中间代码生成以及过程内的控制流分析等基础的分析过程 辅助分析：包括控制流分析等为数据流分析提供支持的分析过程 程序代码建模 漏洞分析系统通常使用树型结构的抽象语法树或者线性的三地址码来描述程序代码的语义。控制流图描述了过程内程序的控制流路径，较为精确的数据流分析通常利用控制流图分析程序执行路径上的某些行为。调用图描述了过程之间的调用关系，是过程间分析需要用到的程序结构 漏洞分析规则 漏洞分析规则是检测程序漏洞的依据。对于分析变量状态的规则，可以使用状态自动机来描述。对于需要分析变量取值的情况，则需要指出应该怎样记录变量的取值，以及在怎样的情况下对变量的取值进行何种的检测 程序漏洞通常和程序中变量的状态或者变量的取值相关。状态自动机可以描述和程序变量状态相关的漏洞分析规则，自动机的状态和变量相应的状态对应 静态漏洞分析 数据流分析可以看做一个根据检测规则在程序的可执行路径上跟踪变量的状态或者变量取值的过程。在该过程中，如果待分析的程序语句是函数调用语句，则需要利用调用图进行过程间的分析，以分析被调用函数的内部代码。另外，数据流分析还可以作为辅助技术，用于完善程序调用图和分析变量别名等 赋值语句、控制转移语句和过程调用语句是数据流分析最关心的三类语句 过程内分析 对于抽象语法树的分析，可以按照程序执行语句的过程从右向左、自底向上地进行分析 对于三地址码的分析，则可以直接识别其操作以及操作相关的变量 在流不敏感分析中，常常使用线性扫描的方式依次分析每一条中间表示形式的语句 流敏感的分析或路径敏感的分析，则根据控制流图进行分析。对控制流图的遍历主要是深度优先和广度优先两种方式 如果在分析某段程序中遇到过程调用语句，就分析其调用过程的内部的代码，完成分析之后再回到原来的程序段继续分析 借鉴基本块的分析，给过程设置上摘要，也包含前置条件和后置条件 前置条件记录对基本块分析前已有的相关分析结果 后置条件是分析基本块后得到的结果 处理分析结果 对检测出的漏洞进行危害程度分类等 方法实现数据流分析使用的程序代码模型主要包括程序代码的中间表示以及一些关键的数据结构，利用程序代码的中间表示可以对程序语句的指令语义进行分析 抽象语法树（AST）是程序抽象语法结构的树状表现形式，其每个内部节点代表一个运算符，该节点的子节点代表这个运算符的运算分量。通过描述控制转移语句的语法结构，抽象语法树在一定程度上也描述了程序的过程内代码的控制流结构 例子： 123456while b ≠ 0 if a &gt; b a := a − b else b := b − areturn a 对应的抽象语法树为： 由一组类似于汇编语言的指令组成，每个指令具有不多于三个的运算分量。每个运算分量都像是一个寄存器 静态单赋值形式（SSA）是一种程序语句或者指令的表示形式，在这种表示形式中，所有的赋值都是针对具有不同名字的变量，也就是说，如果某个变量在不同的程序点被赋值，那么在这些程序点上，该变量在静态单赋值形式的表示中应该使用不同的名字。在使用下标的赋值表示中，变量的名字用于区分程序中的不同的变量，下标用于区分不同程序点上变量的赋值情况。另外，如果在一个程序中，同一个变量可能在两个不同的控制流路径中被赋值，并且在路径交汇后，该变量被使用，那么就需要一种被称为 Φ 函数的的表示规则将变量的赋值合并起来 作用：静态单赋值形式对于数据流分析的意义在于，可以简单而直接地发现变量的赋值和使用情况，以此分析数据的流向并发现程序不安全的行为 控制流图（CFG）是指用于描述程序过程内的控制流的有向图。控制流由节点和有向边组成。典型的节点是基本块（BB），即程序语句的线性序列。有向边表示节点之间存在潜在的控制流路径，通常都带有属性（如if语句的true分支和false分支） 调用图（CG）是描述程序中过程之间的调用和被调用关系的有向图。控制图是一个节点和边的集合，并满足如下原则 对程序中的每个过程都有一个节点 对每个调用点都有一个节点 如果调用点 c 调用了过程 p，就存在一条从 c 的节点到 p 的节点的边 静态漏洞分析数据流分析检测漏洞是利用分析规则按照一定的顺序分析代码中间表示的过程 过程内分析：对于抽象语法树的分析，可以按照程序执行语句的过程从右向左、自底向上地进行分析。对于三地址码的分析，则可以直接识别其操作以及操作相关的变量 过程间分析：如果在分析某段程序中遇到过程调用语句，就分析其调用过程的内部的代码，完成分析之后再回到原来的程序段继续分析。另一种思路是借鉴基本块的分析，给过程设置上摘要，也包含前置条件和后置条件 原文链接","categories":[{"name":"程序分析","slug":"程序分析","permalink":"https://lwy0518.github.io/categories/%E7%A8%8B%E5%BA%8F%E5%88%86%E6%9E%90/"}],"tags":[{"name":"程序分析","slug":"程序分析","permalink":"https://lwy0518.github.io/tags/%E7%A8%8B%E5%BA%8F%E5%88%86%E6%9E%90/"},{"name":"数据流","slug":"数据流","permalink":"https://lwy0518.github.io/tags/%E6%95%B0%E6%8D%AE%E6%B5%81/"},{"name":"Def-Use","slug":"Def-Use","permalink":"https://lwy0518.github.io/tags/Def-Use/"},{"name":"中间表示（IR）","slug":"中间表示（IR）","permalink":"https://lwy0518.github.io/tags/%E4%B8%AD%E9%97%B4%E8%A1%A8%E7%A4%BA%EF%BC%88IR%EF%BC%89/"}],"author":"lwy"},{"title":"EOSIO-Vulneribilities","slug":"EOSIO-Vulneribilities","date":"2021-12-07T07:29:37.000Z","updated":"2021-12-22T02:58:46.385Z","comments":true,"path":"2021/12/07/EOSIO-Vulneribilities/","link":"","permalink":"https://lwy0518.github.io/2021/12/07/EOSIO-Vulneribilities/","excerpt":"EOSIO漏洞复现实验环境 nodeos ：2.0.12 EOSIO.CDT（编译器）：1.2.1 实验数据","text":"EOSIO漏洞复现实验环境 nodeos ：2.0.12 EOSIO.CDT（编译器）：1.2.1 实验数据 准备（前一篇文章已经介绍如何创建账户等等操作） 解锁账户（默认锁定时间较短，可以自己修改配置文件使得时间更长） yourcount：指你自己创建的钱包名 1$ cleos wallet unlock -n yourcount --password EOS Fake Transfer复现过程 存在漏洞的合约示例（test.cpp）： 1234567891011if( code == self || action == ::eosio::string_to_name(&quot;onerror&quot;) || code == N(eosio.token)) &#123; print(&quot;receiver:&quot;, name&#123;receiver&#125;, &quot;, code:&quot;, name&#123;code&#125;, &quot;, action:&quot;, name&#123;action&#125;, &quot;\\n&quot;); notified thiscontract( self ); switch( action ) &#123; case ::eosio::string_to_name( &quot;transfer&quot; ): eosio::execute_action( &amp;thiscontract, &amp;notified::transfer ); break; &#125; &#125; // doSomething()&#125; 漏洞产生的原因 由于eosio.token源代码完全公开的，所以任何人都能复制其源代码，并发布一个token（相同的名字、符号和代码），虚假的EOS和官方的唯一不同就是具有不同的发布人（issuer）。或者直接调用漏洞合约的transfer函数进行转账 过程 创建受害者账户 your key：是你自己创建的公钥，需要把公钥导入到你的钱包以及官方钱包eosio 1$ cleos create account eosio victim4 &quot;your key&quot; 部署测试合约test.cpp cleos set contract + 账户名 + 测试合约的wasm字节码所在目录 + -p + 账户@active（默认权限为active，故可加可不加） 1$ cleos set contract victim4 test/ -p victim4 开始模拟攻击 直接调用test.cpp合约的transfer（主要目的看是否trasnfer中的print是否有输出） cleos push action + 账户名 + 需要调用的action + ‘调用action的参数’ + -p + 转账账户 （+ -j） 1$ cleos push action victim4 transfer &#x27;[&quot;eosio&quot;,&quot;victim4&quot;,&quot;10.0000 EOS&quot;,&quot;inlined call&quot;]&#x27; -p eosio -j 说明：加了一个 -j ，说明结果以json的格式进行输出的 结果显示：测试合约的transfer函数被调用了 查询账户余额 cleos get currency balance eosio.token + 查询账户 + token名（EOS) 1$ cleos get currency balance eosio.token victim4 EOS Forged Transfer Notification复现过程 存在漏洞的合约示例（test.cpp）： 123456789void transfer(account_name from, account_name to, asset quantity, string memo) &#123; print(&quot;\\n Receiving transfer message: from &quot;, name&#123;from&#125;, &quot; to &quot;, name&#123;to&#125;, &quot;,&quot;, quantity, &quot;,&quot;, memo); if (from == _self) &#123; print(&quot;have a vulnerability!&quot;); return; &#125; print(&quot;in eosbet transfer,&quot;, name&#123; from &#125;, &quot;,&quot;, name&#123; to &#125;); // doSomething()&#125; 漏洞产生的原因 攻击者在 EOS 网络中控制两个账户 A（发起攻击的账户） 和 B（将收到的通知立即转发给账户C）。通过账户 A 向账户 B 发送真正的 EOS，如图所示，eosio.token 合约在转账成功后会向 账户A、B 发送 notification。当账户 B 收到 notification后，通过调用require_recipient(C)随即将收到的通知转发给部署受害者智能合约的账户C。 过程 创建攻击者账户sender，用于向另一个由攻击者控制的账户notifier your key：是你自己创建的公钥，需要把公钥导入到你的钱包以及官方钱包eosio 1$ cleos create account eosio sender &quot;your key&quot; 创建账户notifier，用于将收到的转账通知转发给受害者 1$ cleos create account eosio notifier &quot;your key&quot; 创建受害者账户 1$ cleos create account eosio victim5 &quot;your key&quot; 账户notifier部署攻击合约eosbethack.cpp cleos set contract + 账户名 + 测试合约的wasm字节码所在目录 + -p + 账户@active（默认权限为active，故可加可不加） 1$ cleos set contract notifier eosbethack/ -p notifier 账户victim5部署攻击合约eosbet.cpp 1$ cleos set contract victim5 eosbet/ -p victim5 开始模拟攻击 账户sender（攻击者）向账户notifier（攻击者）发送EOS（主要目的看是否trasnfer中的print是否有输出） cleos push action + 账户名 + 需要调用的action + ‘调用action的参数’ + -p + 转账账户 （+ -j） 1$ cleos push action eosio.token transfer &#x27;[&quot;sender&quot;,&quot;notifier&quot;,&quot;10.0000 EOS&quot;,&quot;transfer himself&quot;]&#x27; -p sender -j 说明：加了一个 -j ，说明结果以json的格式进行输出的 结果显示：测试合约的transfer函数被调用了 结果显示：","categories":[{"name":"EOSIO","slug":"EOSIO","permalink":"https://lwy0518.github.io/categories/EOSIO/"}],"tags":[{"name":"EOSIO","slug":"EOSIO","permalink":"https://lwy0518.github.io/tags/EOSIO/"},{"name":"漏洞","slug":"漏洞","permalink":"https://lwy0518.github.io/tags/%E6%BC%8F%E6%B4%9E/"},{"name":"智能合约","slug":"智能合约","permalink":"https://lwy0518.github.io/tags/%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6/"},{"name":"防护","slug":"防护","permalink":"https://lwy0518.github.io/tags/%E9%98%B2%E6%8A%A4/"}],"author":"lwy"},{"title":"构建hexo博客过程","slug":"构建hexo博客过程","date":"2021-12-07T07:23:17.000Z","updated":"2021-12-22T02:58:34.388Z","comments":true,"path":"2021/12/07/构建hexo博客过程/","link":"","permalink":"https://lwy0518.github.io/2021/12/07/%E6%9E%84%E5%BB%BAhexo%E5%8D%9A%E5%AE%A2%E8%BF%87%E7%A8%8B/","excerpt":"环境（Windows） git（git version 2.29.2.windows.3） node（v14.17.0）","text":"环境（Windows） git（git version 2.29.2.windows.3） node（v14.17.0） 本地部署 安装cnpm（国内镜像源很慢） 1$ npm install -g cnpm --registry=https://registry.npm.taobao.org “-g”：表示全局安装 验证是否安装成功： 1$ cnpm -v 设置源： 1$ npm config set registry https://registry.npm.taobao.org 安装hexo 1$ cnpm install -g hexo-cli 验证是否安装成功： 1$ hexo -v 创建一个目录（出错直接删掉目录即可） 12$ mkdir myBlog$ cd myBlog 初始化 1$ hexo init 启动hexo 1$ hexo s 访问地址:localhost:4000 GitHub部署 创建一个仓库，仓库名必须为： 1yourname.github.io 安装插件 1$ cnpm install --save hexo-deployer-git 修改配置文件（在文件最下面修改） Windows 下直接可以用文本打开 其他系统可以用vim 1$ vim _config.yml 添加以下内容 1234deploy: type: git repo: https://github.com:yourname/yourname.github.io.git branch: master 部署到远端（可以提前配置好git账号和密码） 1$ hexo d 访问远程博客 1https://yourname.github.io.git 换主题 下载主题（下载到themes目录下） 1$ git clone https://github.com/litten/hexo-theme-yilia.git themes.yilia 修改 Windows 下直接可以用文本打开 其他系统可以用vim 1$ vim _config.yml 修改以下内容 1theme: yilia 重新生成 1$ hexo clean &amp; hexo g &amp; hexo s 远程部署到github 1$ hexo d 遇到的问题 如遇到这个问题，先检查是否是网络的原因 ，多部署几次，如果还是不行，则采用以下方式： 方法一：在当前目录下操作 12345678## 删除git提交内容文件夹$ rm -rf .deploy_git/##执行$ git config --global core.autocrlf false##最后hexo clean &amp;&amp; hexo g &amp;&amp; hexo d 方法二：有可能是你的git repo配置地址不正确,可以将http方式变更为ssh方式，在当前目录下操作 123456789101112##删除git提交内容文件夹$ vim _config.yml##修改deploy: type: git repo:https://github.com/yourname/yourname.github.io.git -&gt; git@github.com:a956551943/weixiaohui.github.io.git branch: master##最后$ hexo clean &amp;&amp; hexo g &amp;&amp; hexo d 方法三：备选，在当前目录下操作 12345##进入depoly文件夹$ cd .deploy_git/##强制推送$ git push -f 遇到新建博客文章部署之后图片不显示的问题 在Typora中的工具栏中的“格式” –&gt; “图像” –&gt; “全局图像设置”中设置如下，此后会在当前目录下生成包含图片同名的文件 另外，在文章开始部分加上以上命令即可解决图片不显示的问题 1&lt;meta name=&quot;referrer&quot; content=&quot;no-referrer&quot;","categories":[{"name":"Blog","slug":"Blog","permalink":"https://lwy0518.github.io/categories/Blog/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"https://lwy0518.github.io/tags/hexo/"},{"name":"Blog","slug":"Blog","permalink":"https://lwy0518.github.io/tags/Blog/"}],"author":"lwy"}],"categories":[{"name":"偏序","slug":"偏序","permalink":"https://lwy0518.github.io/categories/%E5%81%8F%E5%BA%8F/"},{"name":"SSA","slug":"SSA","permalink":"https://lwy0518.github.io/categories/SSA/"},{"name":"hexo","slug":"hexo","permalink":"https://lwy0518.github.io/categories/hexo/"},{"name":"Markdown","slug":"Markdown","permalink":"https://lwy0518.github.io/categories/Markdown/"},{"name":"程序分析","slug":"程序分析","permalink":"https://lwy0518.github.io/categories/%E7%A8%8B%E5%BA%8F%E5%88%86%E6%9E%90/"},{"name":"EOSIO","slug":"EOSIO","permalink":"https://lwy0518.github.io/categories/EOSIO/"},{"name":"博客","slug":"博客","permalink":"https://lwy0518.github.io/categories/%E5%8D%9A%E5%AE%A2/"},{"name":"Blog","slug":"Blog","permalink":"https://lwy0518.github.io/categories/Blog/"}],"tags":[{"name":"偏序","slug":"偏序","permalink":"https://lwy0518.github.io/tags/%E5%81%8F%E5%BA%8F/"},{"name":"Lattice","slug":"Lattice","permalink":"https://lwy0518.github.io/tags/Lattice/"},{"name":"SSA","slug":"SSA","permalink":"https://lwy0518.github.io/tags/SSA/"},{"name":"gcc","slug":"gcc","permalink":"https://lwy0518.github.io/tags/gcc/"},{"name":"算法","slug":"算法","permalink":"https://lwy0518.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"编译原理","slug":"编译原理","permalink":"https://lwy0518.github.io/tags/%E7%BC%96%E8%AF%91%E5%8E%9F%E7%90%86/"},{"name":"hexo","slug":"hexo","permalink":"https://lwy0518.github.io/tags/hexo/"},{"name":"Blog","slug":"Blog","permalink":"https://lwy0518.github.io/tags/Blog/"},{"name":"Typora","slug":"Typora","permalink":"https://lwy0518.github.io/tags/Typora/"},{"name":"Markdown","slug":"Markdown","permalink":"https://lwy0518.github.io/tags/Markdown/"},{"name":"数据流","slug":"数据流","permalink":"https://lwy0518.github.io/tags/%E6%95%B0%E6%8D%AE%E6%B5%81/"},{"name":"污点分析","slug":"污点分析","permalink":"https://lwy0518.github.io/tags/%E6%B1%A1%E7%82%B9%E5%88%86%E6%9E%90/"},{"name":"依赖关系","slug":"依赖关系","permalink":"https://lwy0518.github.io/tags/%E4%BE%9D%E8%B5%96%E5%85%B3%E7%B3%BB/"},{"name":"Source/Sink","slug":"Source-Sink","permalink":"https://lwy0518.github.io/tags/Source-Sink/"},{"name":"EOSIO","slug":"EOSIO","permalink":"https://lwy0518.github.io/tags/EOSIO/"},{"name":"编译器","slug":"编译器","permalink":"https://lwy0518.github.io/tags/%E7%BC%96%E8%AF%91%E5%99%A8/"},{"name":"漏洞检测","slug":"漏洞检测","permalink":"https://lwy0518.github.io/tags/%E6%BC%8F%E6%B4%9E%E6%A3%80%E6%B5%8B/"},{"name":"静态分析","slug":"静态分析","permalink":"https://lwy0518.github.io/tags/%E9%9D%99%E6%80%81%E5%88%86%E6%9E%90/"},{"name":"Datalog","slug":"Datalog","permalink":"https://lwy0518.github.io/tags/Datalog/"},{"name":"CFG","slug":"CFG","permalink":"https://lwy0518.github.io/tags/CFG/"},{"name":"IR","slug":"IR","permalink":"https://lwy0518.github.io/tags/IR/"},{"name":"中间表示（IR）","slug":"中间表示（IR）","permalink":"https://lwy0518.github.io/tags/%E4%B8%AD%E9%97%B4%E8%A1%A8%E7%A4%BA%EF%BC%88IR%EF%BC%89/"},{"name":"AST","slug":"AST","permalink":"https://lwy0518.github.io/tags/AST/"},{"name":"TAC","slug":"TAC","permalink":"https://lwy0518.github.io/tags/TAC/"},{"name":"RTL","slug":"RTL","permalink":"https://lwy0518.github.io/tags/RTL/"},{"name":"博客","slug":"博客","permalink":"https://lwy0518.github.io/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"智能合约","slug":"智能合约","permalink":"https://lwy0518.github.io/tags/%E6%99%BA%E8%83%BD%E5%90%88%E7%BA%A6/"},{"name":"程序分析","slug":"程序分析","permalink":"https://lwy0518.github.io/tags/%E7%A8%8B%E5%BA%8F%E5%88%86%E6%9E%90/"},{"name":"Def-Use","slug":"Def-Use","permalink":"https://lwy0518.github.io/tags/Def-Use/"},{"name":"漏洞","slug":"漏洞","permalink":"https://lwy0518.github.io/tags/%E6%BC%8F%E6%B4%9E/"},{"name":"防护","slug":"防护","permalink":"https://lwy0518.github.io/tags/%E9%98%B2%E6%8A%A4/"}]}